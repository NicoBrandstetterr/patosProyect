{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import pyproj\n",
    "from IPython.display import display\n",
    "from pyspark.sql import SparkSession,Row\n",
    "from pyspark.sql.functions import col, trim, regexp_replace, lit, when\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombres y Direcciones particulares de cada caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirección donde se ubican los archivos que se cargarán\n",
    "path_case='data_test/'\n",
    "\n",
    "# Nombre que tendrá el caso\n",
    "name_Case='PLP20230104'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remotedesk=False\n",
    "\n",
    "if remotedesk:\n",
    "    path_data='C:/Users/Centro/Documents/DataPLP/'\n",
    "else:\n",
    "    path_data=path_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, trim,regexp_replace\n",
    "# from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# # Cargar el archivo csv en un DataFrame de Spark\n",
    "# plpbarsk = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load(path_data+'plpbar.csv')\n",
    "\n",
    "# # Cambiar los nombres de las columnas\n",
    "# plpbarsk = plpbarsk.toDF(\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"BarName\",\"CMgBar\",\"DemBarP\",\"DemBarE\",\"PerBarP\",\"PerBarE\",\"BarRetP\",\"BarRetE\")\n",
    "\n",
    "# # Eliminar los espacios en las columnas 'BarName' y 'Hidro'\n",
    "# plpbarsk = plpbarsk.withColumn('BarName', regexp_replace('BarName', ' ', ''))\n",
    "# plpbarsk = plpbarsk.withColumn('Hidro', regexp_replace('Hidro', ' ', ''))\n",
    "# plpbarsk = plpbarsk.withColumn(\"id\", col(\"id\").cast(\"int\"))\n",
    "# plpbarsk = plpbarsk.withColumn(\"time\", col(\"time\").cast(\"int\"))\n",
    "# # Seleccionar las columnas 'id' y 'BarName'\n",
    "# indexbussk = plpbarsk.select(\"id\", \"BarName\").dropDuplicates()\n",
    "\n",
    "# ubibarsk = spark.read.options(delimiter=';').format('csv').option('header', 'true').option('inferSchema', 'true').load(f'{path_data}/ubibar.csv')\n",
    "# ubibarsk = ubibarsk.drop('ID')\n",
    "# ubibarsk = ubibarsk.withColumn('LATITUD', regexp_replace('LATITUD', ',', '.').cast('float'))\n",
    "# ubibarsk = ubibarsk.withColumn('LONGITUD', regexp_replace('LONGITUD', ',', '.').cast('float'))\n",
    "# ubibarsk = ubibarsk.toDF(\"BarName\",\"latitud\",\"longitud\")\n",
    "# ubibarsk = ubibarsk.withColumn('BarName',regexp_replace('BarName', \" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----+----+-----------+------+---------------+---------------+---------+---------+---------+---------+---------+---------+----------+\n",
      "|   EmbName| id|type|CVar|effinciency|bus_id|serie_hidro_gen|serie_hidro_ver|min_power|max_power|   VembIn|  VembFin|  VembMin|  VembMax|cotaMínima|\n",
      "+----------+---+----+----+-----------+------+---------------+---------------+---------+---------+---------+---------+---------+---------+----------+\n",
      "|    LMAULE|  1|   E|null|        1.0|     0|              2|           null|      0.0|    100.0|351.52625|  1293.46|      0.0|1453.4093|    2152.1|\n",
      "|  CIPRESES|  2|   E|null|    2.87857|   123|              9|              9|      0.0|    105.0|110.44101|160.53943|4.7163568|174.66032|    1282.8|\n",
      "| PEHUENCHE|  3|   E|null|       1.78|   170|             25|             22|      0.0|    550.0|120.29349|121.61593|106.58308|133.64404|     641.0|\n",
      "|    COLBUN|  4|   E|null|       1.53|   128|             33|           null|      0.0|    474.0|1183.8208| 1553.246| 381.6243| 1553.246|     397.0|\n",
      "|    ELTORO|  5|   E|null|        4.8|   102|             39|             38|      0.0|    450.0|1327.7882|3777.4302|      0.0|5585.8877|    1300.0|\n",
      "|     RAPEL|  6|   E|null|       0.64|   187|           null|           null|      0.0|    375.0|478.58386|563.21246|272.30493|563.21246|     100.5|\n",
      "|CANUTILLAR|  7|   E|null|        2.0|   110|           null|           null|      0.0|    170.2| 745.8976|1065.3785|  449.739|1065.3785|     230.0|\n",
      "|     RALCO|  8|   E|null|   1.657333|   185|             67|             67|      0.0|    690.0| 927.8745| 756.9599| 409.4096|1173.2861|     692.0|\n",
      "|    PANGUE|  9|   E|null|        0.8|   167|             68|             68|     80.0|    450.0| 69.71282| 69.71282|  57.5834|    71.96|     507.0|\n",
      "|PILMAIQUEN| 10|   E|null|       0.27|   184|             84|             84|      7.0|     39.0|132.42528| 89.38706|      0.0| 289.6803|     102.0|\n",
      "+----------+---+----+----+-----------+------+---------------+---------------+---------+---------+---------+---------+---------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "centralsinfo = spark.read.options(delimiter=';').format('csv').option('header', 'true').option('inferSchema', 'true').load(f'{path_data}/centralesinfo.csv')\n",
    "\n",
    "# Cambiar los nombres de las columnas\n",
    "centralsinfo = centralsinfo.toDF('id','CenName','type','CVar','effinciency','bus_id','serie_hidro_gen','serie_hidro_ver','min_power','max_power',\"VembIn\",\"VembFin\",\"VembMin\",\"VembMax\",\"cotaMínima\")\n",
    "\n",
    "# Eliminar los espacios en la columna 'CenName'\n",
    "centralsinfo = centralsinfo.withColumn('CenName', regexp_replace('CenName', \" \", \"\"))\n",
    "\n",
    "# Cambiar las comas a puntos en algunas columnas\n",
    "cols = ['min_power', 'max_power', 'effinciency', 'CVar', 'VembIn', 'VembFin', 'VembMin', 'VembMax', 'cotaMínima']\n",
    "for c in cols:\n",
    "    centralsinfo = centralsinfo.withColumn(c, regexp_replace(c, ',', '.').cast('float'))\n",
    "\n",
    "# Cargando el archivo plpemb.csv en un DataFrame de Spark\n",
    "reservoirs = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load(path_data+'plpemb.csv')\n",
    "\n",
    "# Cambiando los nombres de las columnas\n",
    "reservoirs = reservoirs.withColumnRenamed('Bloque', 'time') \\\n",
    "    .withColumnRenamed('EmbNum', 'id') \\\n",
    "    .withColumnRenamed('EmbNom', 'EmbName')\n",
    "\n",
    "# Removiendo los espacios en las columnas 'EmbName' y 'Hidro'\n",
    "reservoirs = reservoirs.withColumn('EmbName', regexp_replace('EmbName', ' ', ''))\n",
    "reservoirs = reservoirs.withColumn('Hidro', regexp_replace('Hidro', ' ', ''))\n",
    "\n",
    "# Seleccionando las columnas 'id', 'EmbName' y eliminando duplicados\n",
    "indexres = reservoirs.select('id', 'EmbName').dropDuplicates()\n",
    "\n",
    "# Filtrando el DataFrame centralsinfo según el tipo\n",
    "junctionsinfo = centralsinfo.filter(centralsinfo['type'].isin([\"E\", 'S', 'R']))\n",
    "reservoirsinfo = centralsinfo.filter(centralsinfo['type'].isin([\"E\"]))\n",
    "\n",
    "# Renombrando la columna 'CenName' a 'EmbName'\n",
    "reservoirsinfo = reservoirsinfo.withColumnRenamed('CenName', 'EmbName')\n",
    "\n",
    "# Asegurando que 'id' es de tipo Integer\n",
    "reservoirsinfo = reservoirsinfo.withColumn(\"id\", col(\"id\").cast(IntegerType()))\n",
    "indexres = indexres.withColumn(\"id\", col(\"id\").cast(IntegerType()))\n",
    "\n",
    "# Uniendo 'reservoirsinfo' con 'indexres' en base a 'EmbName' y actualizando 'id' en 'reservoirsinfo' con 'id' de 'indexres'\n",
    "reservoirsinfo = reservoirsinfo.join(indexres.withColumnRenamed('id', 'indexres_id'), 'EmbName', 'left')\n",
    "reservoirsinfo = reservoirsinfo.withColumn(\"id\", col(\"indexres_id\").cast(IntegerType())).drop('indexres_id')\n",
    "reservoirsinfo.show()\n",
    "spark.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barra import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plpbar=pd.read_csv(path_data+'plpbar.csv')\n",
    "plpbar.columns=[\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"BarName\",\"CMgBar\",\"DemBarP\",\"DemBarE\",\"PerBarP\",\"PerBarE\",\"BarRetP\",\"BarRetE\"]\n",
    "plpbar['BarName']=plpbar['BarName'].str.replace(\" \",\"\")\n",
    "plpbar[\"Hidro\"] = plpbar[\"Hidro\"].str.replace(\" \", \"\")\n",
    "\n",
    "indexbus=plpbar[['id','BarName']].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "ubibar=pd.read_csv(path_data+'ubibar.csv',sep=';')\n",
    "ubibar=ubibar.drop('ID',axis=1)\n",
    "ubibar['LATITUD']=ubibar['LATITUD'].apply(lambda x:x.replace(',','.')).apply(float)\n",
    "ubibar['LONGITUD']=ubibar['LONGITUD'].apply(lambda x:x.replace(',','.')).apply(float)\n",
    "ubibar.columns=[\"BarName\",\"latitud\",\"longitud\"]\n",
    "ubibar['BarName']=ubibar['BarName'].str.replace(\" \",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BarName</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paposo220</td>\n",
       "      <td>-24.988477</td>\n",
       "      <td>-70.464787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAlmagro220</td>\n",
       "      <td>-26.398285</td>\n",
       "      <td>-70.037306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illapa220</td>\n",
       "      <td>-26.604962</td>\n",
       "      <td>-69.950181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CarreraPinto220</td>\n",
       "      <td>-27.001930</td>\n",
       "      <td>-69.902690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cardones220</td>\n",
       "      <td>-27.489051</td>\n",
       "      <td>-70.385564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BarName    latitud   longitud\n",
       "0        Paposo220 -24.988477 -70.464787\n",
       "1      DAlmagro220 -26.398285 -70.037306\n",
       "2        Illapa220 -26.604962 -69.950181\n",
       "3  CarreraPinto220 -27.001930 -69.902690\n",
       "4      Cardones220 -27.489051 -70.385564"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubibar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          int64\n",
      "BarName    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(indexbus.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plpcen=pd.read_csv(path_data+'plpcen.csv')\n",
    "plpcen.columns=[\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"CenName\",\"tipo\",\"bus_id\",\"BarName\",\"CenQgen\",\"CenPgen\",\"CenEgen\",\"CenInyP\",\"CenInyE\",\"CenRen\",\"CenCVar\",\"CenCostOp\",\"CenPMax\"]\n",
    "plpcen['CenName']=plpcen[\"CenName\"].str.replace(\" \",\"\")\n",
    "plpcen=plpcen.drop([\"CenEgen\",\"CenInyP\",\"CenInyE\",\"CenRen\",\"CenCostOp\",\"CenPMax\"],axis=1)\n",
    "plpcen[\"Hidro\"] = plpcen[\"Hidro\"].str.replace(\" \", \"\")\n",
    "plpcen['tipo']='otros'\n",
    "\n",
    "indexcen=plpcen[['id','CenName','tipo','bus_id']].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "centralsinfo=pd.read_csv(path_data+'centralesinfo.csv',sep=';')\n",
    "centralsinfo.columns=['id','CenName','type','CVar','effinciency','bus_id','serie_hidro_gen','serie_hidro_ver','min_power','max_power',\"VembIn\",\"VembFin\",\"VembMin\",\"VembMax\",\"cotaMínima\"]\n",
    "\n",
    "cols = ['min_power', 'max_power', 'effinciency', 'CVar', 'VembIn', 'VembFin', 'VembMin', 'VembMax', 'cotaMínima']\n",
    "centralsinfo['CenName'] = centralsinfo[\"CenName\"].str.replace(\" \", \"\")\n",
    "for col in cols:\n",
    "    centralsinfo[col] = centralsinfo[col].replace(\",\", \".\", regex=True)\n",
    "hydric_adicional = pd.read_csv(path_data+'hydric_adicional.csv',sep=\";\")\n",
    "\n",
    "\n",
    "tiposcentrales=pd.read_csv(path_data+'centralestype.csv',encoding='latin-1').rename(columns={'cen_name':'CenName'})\n",
    "typecentrals=indexcen.merge(tiposcentrales,on='CenName')\n",
    "\n",
    "for x in range(len(indexcen['id'])):\n",
    "    tipo=typecentrals[typecentrals['CenName']==indexcen['CenName'][x]]['cen_type'].values    \n",
    "    if len(tipo)>0:\n",
    "        plpcen.loc[plpcen['id'] == indexcen['id'][x], 'tipo'] = tipo[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CenName', 'cen_type', 'emission_factor', 'zone', 'is_ernc', 'cenbar',\n",
       "       'censis', 'commitement', 'pmax', 'pmin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiposcentrales=pd.read_csv(path_data+'centralestype.csv',encoding='latin-1').rename(columns={'cen_name':'CenName'})\n",
    "tiposcentrales.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineas import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\4052113039.py:1: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  plplin=pd.read_csv(path_data+'plplin.csv')\n"
     ]
    }
   ],
   "source": [
    "plplin=pd.read_csv(path_data+'plplin.csv')\n",
    "# Cambiando los nombres de las columnas\n",
    "plplin.columns=[\"Hidro\",\"time\",\"TipoEtapa\",\"id\",\"LinName\",\"bus_a\",\"bus_b\",\"LinFluP\",\"LinFluE\",\"capacity\",\"LinUso\",\"LinPerP\",\"LinPerE\",\"LinPer2P\",\"LinPer2E\",\"LinITP\",\"LinITE\"]\n",
    "plplin['LinName']=plplin['LinName'].str.replace(\" \",\"\")\n",
    "plplin[\"Hidro\"] = plplin[\"Hidro\"].str.replace(\" \", \"\")\n",
    "\n",
    "indexlin=plplin[['id','LinName',\"bus_a\",\"bus_b\"]].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "linesinfo=pd.read_csv(path_data+'linesinfo.csv',sep=';')\n",
    "linesinfo.columns=[\"id\",\"LinName\",\"bus_a\",\"bus_b\",\"max_flow_a_b\",\"max_flow_b_a\",\"voltage\",\"r\",\"x\",\"segments\"]\n",
    "linesinfo['LinName']=linesinfo['LinName'].str.replace(\" \",\"\")\n",
    "linesinfo['max_flow_a_b']=(linesinfo[\"max_flow_a_b\"].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "linesinfo['max_flow_b_a']=(linesinfo['max_flow_b_a'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "linesinfo['r']=(linesinfo['r'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "linesinfo['x']=(linesinfo['x'].apply(str)).apply(lambda x:x.replace(',','.')).apply(float)\n",
    "\n",
    "linesfinal=indexlin.drop(['id','bus_a','bus_b'],axis=1).merge(linesinfo,on='LinName')\n",
    "linesfinal['id']=(linesfinal['id']).apply(int)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reservoirs Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralsinfo=pd.read_csv(path_data+'centralesinfo.csv',sep=';')\n",
    "centralsinfo.columns=['id','CenName','type','CVar','effinciency','bus_id','serie_hidro_gen','serie_hidro_ver','min_power','max_power',\"VembIn\",\"VembFin\",\"VembMin\",\"VembMax\",\"cotaMínima\"]\n",
    "\n",
    "cols = ['min_power', 'max_power', 'effinciency', 'CVar', 'VembIn', 'VembFin', 'VembMin', 'VembMax', 'cotaMínima']\n",
    "centralsinfo['CenName'] = centralsinfo[\"CenName\"].str.replace(\" \", \"\")\n",
    "for col in cols:\n",
    "    centralsinfo[col] = centralsinfo[col].replace(\",\", \".\", regex=True)\n",
    "\n",
    "reservoirs = pd.read_csv(path_data+'plpemb.csv')\n",
    "reservoirs.rename(columns={'Bloque': 'time', 'EmbNum': 'id', 'EmbNom': 'EmbName'}, inplace=True)\n",
    "reservoirs['EmbName']=reservoirs['EmbName'].str.replace(\" \",\"\")\n",
    "reservoirs['Hidro']=reservoirs['Hidro'].str.replace(\" \",\"\")\n",
    "\n",
    "indexres = reservoirs[['id','EmbName']].drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "junctionsinfo=centralsinfo[centralsinfo['type'].isin([\"E\",'S','R'])].reset_index(drop=True)\n",
    "reservoirsinfo=centralsinfo[centralsinfo['type'].isin([\"E\"])].reset_index(drop=True)\n",
    "reservoirsinfo.rename(columns={'CenName':'EmbName'}, inplace=True)\n",
    "\n",
    "for i, emb_name in enumerate(reservoirsinfo['EmbName']):\n",
    "    if emb_name in indexres['EmbName'].values:\n",
    "        idx = indexres.index[indexres['EmbName'] == emb_name][0]\n",
    "        reservoirsinfo.at[i, 'id'] = indexres.at[idx, 'id']\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indhor import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indhor = pd.read_csv(path_data+'indhor.csv',encoding='latin-1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre data\n",
    "namedata=name_Case\n",
    "electricTopology=namedata+'/Topology/Electric'\n",
    "hydricTopology=namedata+'/Topology/Hydric'\n",
    "\n",
    "os.makedirs(electricTopology,exist_ok=True)\n",
    "os.makedirs(hydricTopology,exist_ok=True)\n",
    "\n",
    "\n",
    "hidrolist=plpbar['Hidro'].unique()\n",
    "busscenariolist=[]\n",
    "centralscenariolist=[]\n",
    "linescenariolist=[]\n",
    "reservoirscenariolist=[]\n",
    "for hidronum in range(len(hidrolist)):\n",
    "\t# Creamos los directorios\n",
    "\tbusscenario= namedata+f'/Scenarios/{hidronum+1}/Bus'\n",
    "\tcentralscenario=namedata+f'/Scenarios/{hidronum+1}/Centrals'\n",
    "\tlinescenario=namedata+f'/Scenarios/{hidronum+1}/Lines'\n",
    "\treservoirscenario=namedata+f'/Scenarios/{hidronum+1}/Reservoirs'\n",
    "\n",
    "\tos.makedirs(busscenario,exist_ok=True)\n",
    "\tbusscenariolist.append(busscenario)\n",
    "\n",
    "\tos.makedirs(centralscenario,exist_ok=True)\n",
    "\tcentralscenariolist.append(centralscenario)\n",
    "\n",
    "\tos.makedirs(linescenario,exist_ok=True)\n",
    "\tlinescenariolist.append(linescenario)\n",
    "\n",
    "\tos.makedirs(reservoirscenario,exist_ok=True)\n",
    "\treservoirscenariolist.append(reservoirscenario)\n",
    "\n",
    "marginal_cost_path=namedata+f'/Scenarios/Marginal_cost_percentil'\n",
    "line_flow_percentil_path=namedata+f'/Scenarios/Flow_Line_percentil'\n",
    "generation_sistem_path=namedata+f'/Scenarios/Generation_system'\n",
    "os.makedirs(marginal_cost_path,exist_ok=True)\n",
    "os.makedirs(line_flow_percentil_path,exist_ok=True)\n",
    "os.makedirs(generation_sistem_path,exist_ok=True)\n",
    "hydrofile = [x for x in range(1,len(hidrolist)+1)]\n",
    "\n",
    "with open( namedata+'/Scenarios/hydrologies.json', 'w') as f:\n",
    "  json.dump(hydrofile, f)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables indicadoras de cantidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de horas de bloques temporales del proyecto\n",
    "time=plplin['time'].max()\n",
    "\n",
    "# Número de barras\n",
    "nbus=len(indexbus['id'])\n",
    "lbus=list(indexbus['id'])\n",
    "\n",
    "# Número de generadores\n",
    "ngen=len(indexcen['id'])\n",
    "\n",
    "# Número de lineas\n",
    "nlin=len(indexlin['id'])\n",
    "\n",
    "# Número de Reservoirs\n",
    "nres = len(reservoirs['EmbName'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función generadora de latitudes y longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aleatory_direction():\n",
    "    latitud=-random.uniform(10, 85)\n",
    "    longitud=-random.uniform(10, 85)\n",
    "    return latitud,longitud\n",
    "\n",
    "def LatLon_To_XY(Lat,Lon):\n",
    "  B = pyproj.Transformer.from_crs(4326,20049) #WGS84->EPSG:20049 (Chile 2021/UTM zone 19S)\n",
    "  UTMx, UTMy = B.transform(Lat,Lon)\n",
    "  return UTMx, UTMy\n",
    "\n",
    "def XY_To_LatLon(x,y):\n",
    "  B = pyproj.Transformer.from_crs(20049,4326)\n",
    "  Lat, Lon = B.transform(x,y)\n",
    "  return Lat, Lon\n",
    "\n",
    "def valorXY(LatP, LonP, scale):\n",
    "  A = LatLon_To_XY(LatP, LonP)\n",
    "  X,Y = A[0]*scale, A[1]*scale\n",
    "  return Y,X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloques a Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indhor2=indhor.drop('Hora',axis=1).groupby(['Año','Mes'])\n",
    "indhorlist=[]\n",
    "for x in indhor2:\n",
    "    indhorlist.append([str(x[1]['Bloque'].min()),str(x[1]['Bloque'].max()),str(x[0])])\n",
    "with open( namedata+'/Scenarios/indhor.json', 'w') as f:\n",
    "  json.dump(indhorlist, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación por Sistema por Hidrología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim1 lista\n",
      "Sim2 lista\n",
      "Sim3 lista\n",
      "Sim4 lista\n",
      "Sim5 lista\n",
      "Sim6 lista\n",
      "Sim7 lista\n",
      "Sim8 lista\n",
      "Sim9 lista\n",
      "Sim10 lista\n",
      "Sim11 lista\n",
      "Sim12 lista\n",
      "Sim13 lista\n",
      "Sim14 lista\n",
      "MEDIA lista\n"
     ]
    }
   ],
   "source": [
    "typegenlist=typecentrals.cen_type.unique()\n",
    "for i,hydro in enumerate(hidrolist):\n",
    "    print(hydro+\" lista\")\n",
    "    dic_type_gen={}\n",
    "    auxdf = plpcen[plpcen['Hidro']==hydro]\n",
    "    auxdf=auxdf.groupby(['tipo','time'])['CenPgen'].sum().reset_index().groupby('tipo')\n",
    "    for group in auxdf:\n",
    "        tipo = group[0]\n",
    "        df_tipo = group[1]\n",
    "        dic_type_gen[tipo] = [row for row in df_tipo[['time', 'CenPgen']].to_dict(orient='records')]\n",
    "    \n",
    "    with open(generation_sistem_path+f'/generation_system_{i+1}.json', 'w') as f:\n",
    "        json.dump(dic_type_gen, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentiles Costo Marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos de AltoNorte110 [1/229]\n",
      "Procesando datos de Andes220 [2/229]\n",
      "Procesando datos de Andes345 [3/229]\n",
      "Procesando datos de Angamos220 [4/229]\n",
      "Procesando datos de Antofagasta110 [5/229]\n",
      "Procesando datos de Arica066 [6/229]\n",
      "Procesando datos de Atacama220_BP1 [7/229]\n",
      "Procesando datos de Barriles220 [8/229]\n",
      "Procesando datos de Cachiyuyal220 [9/229]\n",
      "Procesando datos de Capricornio110 [10/229]\n",
      "Procesando datos de Capricornio220 [11/229]\n",
      "Procesando datos de Cardones110 [12/229]\n",
      "Procesando datos de Cardones220 [13/229]\n",
      "Procesando datos de Chacaya220 [14/229]\n",
      "Procesando datos de Chuquicamata100 [15/229]\n",
      "Procesando datos de Chuquicamata220 [16/229]\n",
      "Procesando datos de Cochrane220 [17/229]\n",
      "Procesando datos de Collahuasi220 [18/229]\n",
      "Procesando datos de Conchi220 [19/229]\n",
      "Procesando datos de Condores220 [20/229]\n",
      "Procesando datos de CPinto220 [21/229]\n",
      "Procesando datos de Crucero220 [22/229]\n",
      "Procesando datos de Parinas500 [23/229]\n",
      "Procesando datos de Cumbre500 [24/229]\n",
      "Procesando datos de DAlmagro110 [25/229]\n",
      "Procesando datos de DAlmagro220 [26/229]\n",
      "Procesando datos de DArica066 [27/229]\n",
      "Procesando datos de Desalant110 [28/229]\n",
      "Procesando datos de Domeyko220 [29/229]\n",
      "Procesando datos de DonaCarmen220 [30/229]\n",
      "Procesando datos de DonGoyo220 [31/229]\n",
      "Procesando datos de DonHector220 [32/229]\n",
      "Procesando datos de ElCobre220 [33/229]\n",
      "Procesando datos de ElLoa220 [34/229]\n",
      "Procesando datos de ElNegro110 [35/229]\n",
      "Procesando datos de ElPenon110 [36/229]\n",
      "Procesando datos de ElTesoro220 [37/229]\n",
      "Procesando datos de Esmeralda110 [38/229]\n",
      "Procesando datos de Esmeralda220 [39/229]\n",
      "Procesando datos de Esperanza220 [40/229]\n",
      "Procesando datos de Francisco220 [41/229]\n",
      "Procesando datos de Guacolda220 [42/229]\n",
      "Procesando datos de Huasco110 [43/229]\n",
      "Procesando datos de Kapatur220_BP1 [44/229]\n",
      "Procesando datos de Laberinto220 [45/229]\n",
      "Procesando datos de LaCebada220 [46/229]\n",
      "Procesando datos de LaCruz220 [47/229]\n",
      "Procesando datos de Lagunas220 [48/229]\n",
      "Procesando datos de LaNegra110 [49/229]\n",
      "Procesando datos de LosChangos220 [50/229]\n",
      "Procesando datos de LosChangos500 [51/229]\n",
      "Procesando datos de LPalmas220 [52/229]\n",
      "Procesando datos de LVilos220 [53/229]\n",
      "Procesando datos de Maitencillo110 [54/229]\n",
      "Procesando datos de Maitencillo220 [55/229]\n",
      "Procesando datos de Mantos220 [56/229]\n",
      "Procesando datos de MariaElena220 [57/229]\n",
      "Procesando datos de Mejillones110 [58/229]\n",
      "Procesando datos de Mejillones220 [59/229]\n",
      "Procesando datos de Miraje220 [60/229]\n",
      "Procesando datos de MRedondo220 [61/229]\n",
      "Procesando datos de Norgener220 [62/229]\n",
      "Procesando datos de NvaCardones500 [63/229]\n",
      "Procesando datos de NvaMaitencillo500 [64/229]\n",
      "Procesando datos de NvaPAzucar500 [65/229]\n",
      "Procesando datos de NvaVictoria220 [66/229]\n",
      "Procesando datos de NvaZaldivar220 [67/229]\n",
      "Procesando datos de Oeste220 [68/229]\n",
      "Procesando datos de Ohiggins220_BP1 [69/229]\n",
      "Procesando datos de Palestina220 [70/229]\n",
      "Procesando datos de PAlmonte110 [71/229]\n",
      "Procesando datos de PAlmonte220 [72/229]\n",
      "Procesando datos de Pampa110 [73/229]\n",
      "Procesando datos de Paposo220 [74/229]\n",
      "Procesando datos de PAzucar110 [75/229]\n",
      "Procesando datos de PAzucar220 [76/229]\n",
      "Procesando datos de PColorada220 [77/229]\n",
      "Procesando datos de Portada110 [78/229]\n",
      "Procesando datos de PuntaSierra220 [79/229]\n",
      "Procesando datos de S-AA100 [80/229]\n",
      "Procesando datos de Salar110 [81/229]\n",
      "Procesando datos de Salar220 [82/229]\n",
      "Procesando datos de Salta345 [83/229]\n",
      "Procesando datos de S-Km6100 [84/229]\n",
      "Procesando datos de Talinay220 [85/229]\n",
      "Procesando datos de Tamaya110 [86/229]\n",
      "Procesando datos de Tarapaca220 [87/229]\n",
      "Procesando datos de TO_Enlace220 [88/229]\n",
      "Procesando datos de Tocopilla110 [89/229]\n",
      "Procesando datos de Tocopilla220_BP1 [90/229]\n",
      "Procesando datos de AJahuel110 [91/229]\n",
      "Procesando datos de AJahuel154 [92/229]\n",
      "Procesando datos de AJahuel220 [93/229]\n",
      "Procesando datos de AJahuel500 [94/229]\n",
      "Procesando datos de Alfalfal220 [95/229]\n",
      "Procesando datos de Almendros110 [96/229]\n",
      "Procesando datos de Almendros220 [97/229]\n",
      "Procesando datos de AMelipilla220 [98/229]\n",
      "Procesando datos de Ancoa220 [99/229]\n",
      "Procesando datos de Ancoa500 [100/229]\n",
      "Procesando datos de Angostura220 [101/229]\n",
      "Procesando datos de Antuco220 [102/229]\n",
      "Procesando datos de Apoquindo110 [103/229]\n",
      "Procesando datos de ASanta110 [104/229]\n",
      "Procesando datos de ASanta220 [105/229]\n",
      "Procesando datos de Batuco110 [106/229]\n",
      "Procesando datos de Bocamina154 [107/229]\n",
      "Procesando datos de Buin110 [108/229]\n",
      "Procesando datos de Candelaria220 [109/229]\n",
      "Procesando datos de Canutillar220 [110/229]\n",
      "Procesando datos de Cautin220 [111/229]\n",
      "Procesando datos de Charrua066 [112/229]\n",
      "Procesando datos de Charrua154 [113/229]\n",
      "Procesando datos de Charrua220 [114/229]\n",
      "Procesando datos de Charrua500 [115/229]\n",
      "Procesando datos de Chena110 [116/229]\n",
      "Procesando datos de Chena220 [117/229]\n",
      "Procesando datos de Chillan154 [118/229]\n",
      "Procesando datos de Chiloe110 [119/229]\n",
      "Procesando datos de Cholguan066 [120/229]\n",
      "Procesando datos de Cholguan220 [121/229]\n",
      "Procesando datos de Chonchi110 [122/229]\n",
      "Procesando datos de Cipreses154 [123/229]\n",
      "Procesando datos de Ciruelos220 [124/229]\n",
      "Procesando datos de CNavia110 [125/229]\n",
      "Procesando datos de CNavia220 [126/229]\n",
      "Procesando datos de CNavia220_Desf [127/229]\n",
      "Procesando datos de Colbun220 [128/229]\n",
      "Procesando datos de Concepcion066 [129/229]\n",
      "Procesando datos de Concepcion154 [130/229]\n",
      "Procesando datos de Constitucion066 [131/229]\n",
      "Procesando datos de Coronel066 [132/229]\n",
      "Procesando datos de Coronel154 [133/229]\n",
      "Procesando datos de Degan110 [134/229]\n",
      "Procesando datos de Duqueco220 [135/229]\n",
      "Procesando datos de ElSalto110 [136/229]\n",
      "Procesando datos de EntreRios220 [137/229]\n",
      "Procesando datos de EntreRios500 [138/229]\n",
      "Procesando datos de Florida110 [139/229]\n",
      "Procesando datos de Fopaco154 [140/229]\n",
      "Procesando datos de Horcones066 [141/229]\n",
      "Procesando datos de Hualpen154 [142/229]\n",
      "Procesando datos de Hualpen220 [143/229]\n",
      "Procesando datos de Itahue154 [144/229]\n",
      "Procesando datos de Lagunillas154 [145/229]\n",
      "Procesando datos de Lagunillas220 [146/229]\n",
      "Procesando datos de Lautaro066 [147/229]\n",
      "Procesando datos de Linares154 [148/229]\n",
      "Procesando datos de LoAguirre220 [149/229]\n",
      "Procesando datos de LoAguirre500 [150/229]\n",
      "Procesando datos de LoEspejo110 [151/229]\n",
      "Procesando datos de LVegas110 [152/229]\n",
      "Procesando datos de LVegas110_exp [153/229]\n",
      "Procesando datos de Malloa154 [154/229]\n",
      "Procesando datos de Mapal154 [155/229]\n",
      "Procesando datos de Maule154 [156/229]\n",
      "Procesando datos de Miraflores110 [157/229]\n",
      "Procesando datos de Molinos110 [158/229]\n",
      "Procesando datos de Mulchen220 [159/229]\n",
      "Procesando datos de Nogales220 [160/229]\n",
      "Procesando datos de NvaCauquenes220 [161/229]\n",
      "Procesando datos de NvaNirivilo220 [162/229]\n",
      "Procesando datos de Ochagavia110 [163/229]\n",
      "Procesando datos de Pachacama110 [164/229]\n",
      "Procesando datos de Paine154 [165/229]\n",
      "Procesando datos de PAltoCmpc110 [166/229]\n",
      "Procesando datos de Pangue220 [167/229]\n",
      "Procesando datos de Parral154 [168/229]\n",
      "Procesando datos de PCortes154 [169/229]\n",
      "Procesando datos de Pehuenche220 [170/229]\n",
      "Procesando datos de Petroquim154 [171/229]\n",
      "Procesando datos de Pichirrahue220 [172/229]\n",
      "Procesando datos de Pichirropulli220 [173/229]\n",
      "Procesando datos de Pid-Pid110 [174/229]\n",
      "Procesando datos de Pillanlelbun066 [175/229]\n",
      "Procesando datos de PMontt220 [176/229]\n",
      "Procesando datos de PNegro220 [177/229]\n",
      "Procesando datos de Polpaico220 [178/229]\n",
      "Procesando datos de Polpaico500 [179/229]\n",
      "Procesando datos de PPeuco110 [180/229]\n",
      "Procesando datos de Quillota110 [181/229]\n",
      "Procesando datos de Quillota220 [182/229]\n",
      "Procesando datos de Quintero220 [183/229]\n",
      "Procesando datos de Rahue220 [184/229]\n",
      "Procesando datos de Ralco220 [185/229]\n",
      "Procesando datos de Rancagua154 [186/229]\n",
      "Procesando datos de Rapel220 [187/229]\n",
      "Procesando datos de Renca110 [188/229]\n",
      "Procesando datos de RioTolten220 [189/229]\n",
      "Procesando datos de Rucue220 [190/229]\n",
      "Procesando datos de SanLuis220 [191/229]\n",
      "Procesando datos de SantaElvira066 [192/229]\n",
      "Procesando datos de SantaMaria220 [193/229]\n",
      "Procesando datos de SantaMarta220 [194/229]\n",
      "Procesando datos de Sauzal110_BP1 [195/229]\n",
      "Procesando datos de Sauzal110_BP2 [196/229]\n",
      "Procesando datos de Sauzal154 [197/229]\n",
      "Procesando datos de SCristobal110 [198/229]\n",
      "Procesando datos de SFcoMost066 [199/229]\n",
      "Procesando datos de SJavier066 [200/229]\n",
      "Procesando datos de SMiguel066 [201/229]\n",
      "Procesando datos de StaRosa110 [202/229]\n",
      "Procesando datos de SVicente154 [203/229]\n",
      "Procesando datos de Talca066 [204/229]\n",
      "Procesando datos de Temuco066 [205/229]\n",
      "Procesando datos de Temuco220 [206/229]\n",
      "Procesando datos de Teno154 [207/229]\n",
      "Procesando datos de Tilcoco154 [208/229]\n",
      "Procesando datos de Tineo220 [209/229]\n",
      "Procesando datos de Tinguiririca220 [210/229]\n",
      "Procesando datos de Tinguiririca154 [211/229]\n",
      "Procesando datos de Torquemada110 [212/229]\n",
      "Procesando datos de Trupan220 [213/229]\n",
      "Procesando datos de Tuniche154_I [214/229]\n",
      "Procesando datos de Tuniche154_II [215/229]\n",
      "Procesando datos de Valdivia220 [216/229]\n",
      "Procesando datos de Ventanas110 [217/229]\n",
      "Procesando datos de Ventanas220 [218/229]\n",
      "Procesando datos de Guindo066 [219/229]\n",
      "Procesando datos de Guindo220 [220/229]\n",
      "Procesando datos de Mauro220 [221/229]\n",
      "Procesando datos de Chiloe220 [222/229]\n",
      "Procesando datos de PAzucar220_aux [223/229]\n",
      "Procesando datos de PAzucar220_aux2 [224/229]\n",
      "Procesando datos de Nogales220_aux [225/229]\n",
      "Procesando datos de Ancoa500auxS [226/229]\n",
      "Procesando datos de Pichirropulli220AuxS [227/229]\n",
      "Procesando datos de Pichirropulli220Aux [228/229]\n",
      "Procesando datos de Charrua220Aux [229/229]\n"
     ]
    }
   ],
   "source": [
    "def percentilCM():\n",
    "    datos_bar = plpbar[['Hidro', 'time','id', 'BarName', 'CMgBar']]\n",
    "    lista_bar = datos_bar.BarName.unique()\n",
    "\n",
    "    i=1\n",
    "    for barra in lista_bar:\n",
    "        print(f'Procesando datos de {barra} [{i}/{len(lista_bar)}]')\n",
    "        data_barraTx = datos_bar.loc[(datos_bar.BarName == barra)]\n",
    "        idbar=data_barraTx['id'].unique()[0]\n",
    "        data_barraTx = data_barraTx[~(data_barraTx['Hidro'] == 'MEDIA')]\n",
    "        Promedio = data_barraTx[['time','CMgBar']]\n",
    "        xy =Promedio.groupby(['time']).mean()\n",
    "        \n",
    "        data_barraTx = data_barraTx.groupby(['time']).agg(perc0=('CMgBar', lambda x: x.quantile(0.0)),\n",
    "                                                                perc20=(\n",
    "                                                                    'CMgBar', lambda x: x.quantile(0.2)),\n",
    "                                                                perc80=(\n",
    "                                                                    'CMgBar', lambda x: x.quantile(0.8)),\n",
    "                                                                perc100=('CMgBar', lambda x: x.quantile(1)))\n",
    "\n",
    "        data_barraTx['promedio'] = xy\n",
    "        data_barraTx = data_barraTx.assign(name=barra)\n",
    "        data_barraTx = data_barraTx.assign(id=idbar)\n",
    "        data_barraTx.reset_index(inplace=True)\n",
    "        data_barraTx=data_barraTx[['id','time','name','perc0','perc20','perc80','perc100','promedio']]\n",
    "        data_barraTx.to_json(marginal_cost_path+f\"/bus_{idbar}.json\",orient='records')\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "percentilCM()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentiles Flujos de Lineas de Transmisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando datos de Andes220->Oeste220 [1/325]\n",
      "Procesando datos de Andes345->Andes220 [2/325]\n",
      "Procesando datos de Angamos220->Kapatur220 [3/325]\n",
      "Procesando datos de Antofag110->Desalant110 [4/325]\n",
      "Procesando datos de Antofag110->LaNegra110 [5/325]\n",
      "Procesando datos de Atacama220->OHiggins220 [6/325]\n",
      "Procesando datos de Cachiyuyal220->DAlmagro220 [7/325]\n",
      "Procesando datos de Capricorn220->Capricorn110 [8/325]\n",
      "Procesando datos de Capricornio110->Antofag110 [9/325]\n",
      "Procesando datos de Capricornio110->ElNegro110 [10/325]\n",
      "Procesando datos de Capricornio110->LaNegra110 [11/325]\n",
      "Procesando datos de Capricornio220->Mantos220 [12/325]\n",
      "Procesando datos de Cardones220->Cardones110 [13/325]\n",
      "Procesando datos de Cardones220->CPinto220 [14/325]\n",
      "Procesando datos de Chacaya220->Capricornio220 [15/325]\n",
      "Procesando datos de Chacaya220->ElCobre220 [16/325]\n",
      "Procesando datos de Chacaya220->Mejillones220 [17/325]\n",
      "Procesando datos de Chuqui220->Chuqui100 [18/325]\n",
      "Procesando datos de Chuquicamata100->S-AA100 [19/325]\n",
      "Procesando datos de Chuquicamata100->S-Km6100 [20/325]\n",
      "Procesando datos de Cochrane220->Encuentro220 [21/325]\n",
      "Procesando datos de Condores220->PAlmonte220 [22/325]\n",
      "Procesando datos de Crucero220->Barriles220 [23/325]\n",
      "Procesando datos de Crucero220->Chacaya220 [24/325]\n",
      "Procesando datos de Crucero220->Chuquicamata220 [25/325]\n",
      "Procesando datos de Crucero220->Conchi220 [26/325]\n",
      "Procesando datos de Crucero220->ElLoa220 [27/325]\n",
      "Procesando datos de Crucero220->Laberinto220 [28/325]\n",
      "Procesando datos de Crucero220->LaCruz220 [29/325]\n",
      "Procesando datos de Crucero220->MariaElena220 [30/325]\n",
      "Procesando datos de Crucero220->Salar220 [31/325]\n",
      "Procesando datos de Crucero220->Tocopilla220 [32/325]\n",
      "Procesando datos de Cumbre500_SC->NvaCardones500_SC [33/325]\n",
      "Procesando datos de Cumbre500->NvaCardones500 [34/325]\n",
      "Procesando datos de DAlmagro220->DAlmagro110 [35/325]\n",
      "Procesando datos de DArica066->Arica066 [36/325]\n",
      "Procesando datos de Arica066->PAlmonte110 [37/325]\n",
      "Procesando datos de DonaCarmen220->Nogales220_aux [38/325]\n",
      "Procesando datos de DonGoyo220->LaCebada220 [39/325]\n",
      "Procesando datos de DonGoyo220->Talinay220 [40/325]\n",
      "Procesando datos de DonHector220->PColorada220 [41/325]\n",
      "Procesando datos de ElCobre220->Esperanza220 [42/325]\n",
      "Procesando datos de ElLoa220->Tocopilla220 [43/325]\n",
      "Procesando datos de ElNegro110->AltoNorte110 [44/325]\n",
      "Procesando datos de ElTesoro220->Esperanza220 [45/325]\n",
      "Procesando datos de Encuentro220->Colla220 [46/325]\n",
      "Procesando datos de Encuentro220->ElTesoro220 [47/325]\n",
      "Procesando datos de Encuentro220->Lagunas220 [48/325]\n",
      "Procesando datos de Encuentro220->Miraje220 [49/325]\n",
      "Procesando datos de Esmeralda110->Portada110 [50/325]\n",
      "Procesando datos de Esmeralda220->Esmeralda110 [51/325]\n",
      "Procesando datos de Francisco220->DAlmagro220 [52/325]\n",
      "Procesando datos de GasAta220->Esmeralda220 [53/325]\n",
      "Procesando datos de Guacolda220->Maitenc220 [54/325]\n",
      "Procesando datos de Illapa220->Cumbre500 [55/325]\n",
      "Procesando datos de Illapa220->DAlmagro220 [56/325]\n",
      "Procesando datos de Kapatur220->Laberinto220 [57/325]\n",
      "Procesando datos de Kapatur220->Ohiggins220 [58/325]\n",
      "Procesando datos de Laberinto220->ElCobre220 [59/325]\n",
      "Procesando datos de Laberinto220->Mantos220 [60/325]\n",
      "Procesando datos de Laberinto220->NvaZald220 [61/325]\n",
      "Procesando datos de Laberinto220->Oeste220 [62/325]\n",
      "Procesando datos de LaCebada220->MRedondo220 [63/325]\n",
      "Procesando datos de LaCebada220->PuntaSierra220 [64/325]\n",
      "Procesando datos de Lagunas220->Collahuasi220 [65/325]\n",
      "Procesando datos de Lagunas220->NvaVictoria220 [66/325]\n",
      "Procesando datos de Lagunas220->Tarapaca220 [67/325]\n",
      "Procesando datos de LaNegra110->AltoNorte110 [68/325]\n",
      "Procesando datos de LosChangos220->Kapatur220 [69/325]\n",
      "Procesando datos de LosChangos500->Cumbre500 [70/325]\n",
      "Procesando datos de LosChangos500->Parinas500 [71/325]\n",
      "Procesando datos de Parinas500->Cumbre500 [72/325]\n",
      "Procesando datos de Likanantai500->Parinas500 [73/325]\n",
      "Procesando datos de LosChangos500->Kimal500_I [74/325]\n",
      "Procesando datos de LosChangos500->Kimal500_II [75/325]\n",
      "Procesando datos de LosChangos500->LosChangos220 [76/325]\n",
      "Procesando datos de LPalmas220->LVilos220 [77/325]\n",
      "Procesando datos de LVilos220->DonaCarmen220 [78/325]\n",
      "Procesando datos de LVilos220->Nogales220_aux [79/325]\n",
      "Procesando datos de Maitenc110->Cardones110 [80/325]\n",
      "Procesando datos de Maitenc110->Huasco110 [81/325]\n",
      "Procesando datos de Maitenc220->Cardones220 [82/325]\n",
      "Procesando datos de Maitenc220->DonHector220 [83/325]\n",
      "Procesando datos de Maitenc220->Maitenc110 [84/325]\n",
      "Procesando datos de Maitencillo220->PColorada220_II [85/325]\n",
      "Procesando datos de MariaElena220->Lagunas220 [86/325]\n",
      "Procesando datos de MariaElena220->NvaVictoria220 [87/325]\n",
      "Procesando datos de Mauro220->Quillota220 [88/325]\n",
      "Procesando datos de Mejillones110->Pampa110 [89/325]\n",
      "Procesando datos de Mejillones220->Mejillones110 [90/325]\n",
      "Procesando datos de Mejillones220->OHiggins220 [91/325]\n",
      "Procesando datos de Miraje220->Atacama220 [92/325]\n",
      "Procesando datos de Miraje220->TOEnlace220 [93/325]\n",
      "Procesando datos de MRedondo220->PuntaSierra220 [94/325]\n",
      "Procesando datos de Norgener220->Barriles220 [95/325]\n",
      "Procesando datos de Norgener220->LaCruz220 [96/325]\n",
      "Procesando datos de NvaCardones500->Cardones220 [97/325]\n",
      "Procesando datos de NvaMaitenc500->Maitenc220 [98/325]\n",
      "Procesando datos de NvaMaitenc500->NvaCardones500 [99/325]\n",
      "Procesando datos de NvaPAzucar500_SC->NvaMaitenc500_SC [100/325]\n",
      "Procesando datos de NvaPAzucar500_SC->Polpaico500_I_SC [101/325]\n",
      "Procesando datos de NvaPAzucar500_SC->Polpaico500_II_SC [102/325]\n",
      "Procesando datos de NvaPAzucar500->NvaMaitenc500 [103/325]\n",
      "Procesando datos de NvaPAzucar500->PAzucar220 [104/325]\n",
      "Procesando datos de NvaPAzucar500->Polpaico500_I [105/325]\n",
      "Procesando datos de NvaPAzucar500->Polpaico500_II [106/325]\n",
      "Procesando datos de NvaZaldivar220->Andes220 [107/325]\n",
      "Procesando datos de NvaZaldivar220->Domeyko220 [108/325]\n",
      "Procesando datos de OHiggins220->Domeyko220 [109/325]\n",
      "Procesando datos de OHiggins220->Palestina220 [110/325]\n",
      "Procesando datos de Palestina220->Domeyko220 [111/325]\n",
      "Procesando datos de PAlmonte220->Lagunas220 [112/325]\n",
      "Procesando datos de PAlmonte220->PAlmonte110 [113/325]\n",
      "Procesando datos de Pampa110->Desalant110 [114/325]\n",
      "Procesando datos de Paposo220->Cachiyuyal220 [115/325]\n",
      "Procesando datos de Paposo220->Francisco220 [116/325]\n",
      "Procesando datos de PAzucar110->ElPenon110 [117/325]\n",
      "Procesando datos de PAzucar110->Maitenc110 [118/325]\n",
      "Procesando datos de PAzucar220_aux->DonGoyo220 [119/325]\n",
      "Procesando datos de PAzucar220->PAzucar110 [120/325]\n",
      "Procesando datos de PAzucar220->PuntaSierra220 [121/325]\n",
      "Procesando datos de PColorada220->PAzucar220 [122/325]\n",
      "Procesando datos de PColorada220->PAzucar220_II [123/325]\n",
      "Procesando datos de PuntaSierra220->LPalmas220 [124/325]\n",
      "Procesando datos de PuntaSierra220->Mauro220 [125/325]\n",
      "Procesando datos de Salar110->Salar220 [126/325]\n",
      "Procesando datos de Salar220->Chuquicamata220 [127/325]\n",
      "Procesando datos de SalardelCarmen [128/325]\n",
      "Procesando datos de Salta345->Andes345 [129/325]\n",
      "Procesando datos de S-Km6100->Salar110 [130/325]\n",
      "Procesando datos de Talinay220->LaCebada220 [131/325]\n",
      "Procesando datos de Tamaya110->S-AA100_3B [132/325]\n",
      "Procesando datos de Tamaya110->Salar110_4B [133/325]\n",
      "Procesando datos de Tarapaca220->Condores220 [134/325]\n",
      "Procesando datos de TO_Enlace220->Atacama220 [135/325]\n",
      "Procesando datos de Tocopilla110->S-AA100 [136/325]\n",
      "Procesando datos de Tocopilla110->Tamaya110 [137/325]\n",
      "Procesando datos de Tocopilla220->Tocopi110 [138/325]\n",
      "Procesando datos de AJahuel110->Sauzal110_BP1 [139/325]\n",
      "Procesando datos de AJahuel154->Paine154 [140/325]\n",
      "Procesando datos de AJahuel154->Tuniche154_II [141/325]\n",
      "Procesando datos de AJahuel220->AJahuel110 [142/325]\n",
      "Procesando datos de AJahuel220->AJahuel154 [143/325]\n",
      "Procesando datos de AJahuel220->Buin110 [144/325]\n",
      "Procesando datos de AJahuel220->Chena220 [145/325]\n",
      "Procesando datos de AJahuel220->PAltoCmpc110 [146/325]\n",
      "Procesando datos de AJahuel220->SantaMarta220 [147/325]\n",
      "Procesando datos de AJahuel500->AJahuel220 [148/325]\n",
      "Procesando datos de Alfalfal220->Almendros220 [149/325]\n",
      "Procesando datos de Almendros110->Apoquindo110 [150/325]\n",
      "Procesando datos de Almendros220->AJahuel220 [151/325]\n",
      "Procesando datos de Almendros220->Almendros110 [152/325]\n",
      "Procesando datos de AMelipill220->LoAguirre220 [153/325]\n",
      "Procesando datos de Ancoa220->Itahue154 [154/325]\n",
      "Procesando datos de Ancoa500->AJahuel500 [155/325]\n",
      "Procesando datos de Ancoa500->Ancoa220 [156/325]\n",
      "Procesando datos de Angostura220->Mulchen220 [157/325]\n",
      "Procesando datos de Antuco220->Charrua220 [158/325]\n",
      "Procesando datos de Antuco220->Trupan220 [159/325]\n",
      "Procesando datos de Apoquindo110->ElSalto110 [160/325]\n",
      "Procesando datos de ASanta110->Mirafl110 [161/325]\n",
      "Procesando datos de ASanta220->ASanta110 [162/325]\n",
      "Procesando datos de ASanta220->ASanta110_2 [163/325]\n",
      "Procesando datos de Batuco110->PPeuco110 [164/325]\n",
      "Procesando datos de Batuco110->PPeuco110_I [165/325]\n",
      "Procesando datos de Bocamina154->Coronel154 [166/325]\n",
      "Procesando datos de Buin110->LoEspejo110 [167/325]\n",
      "Procesando datos de Candela220->AJahuel220 [168/325]\n",
      "Procesando datos de Canutilla220->PMontt220 [169/325]\n",
      "Procesando datos de Cautin220->RioTolten220 [170/325]\n",
      "Procesando datos de Charrua066->Cholguan066 [171/325]\n",
      "Procesando datos de Charrua154->Charrua066 [172/325]\n",
      "Procesando datos de Charrua154->Chillan154 [173/325]\n",
      "Procesando datos de Charrua154->Conce154 [174/325]\n",
      "Procesando datos de Charrua154->Parral154 [175/325]\n",
      "Procesando datos de Charrua220->Charrua154 [176/325]\n",
      "Procesando datos de Charrua220->Charrua500 [177/325]\n",
      "Procesando datos de Charrua220->Conce154 [178/325]\n",
      "Procesando datos de Charrua220Aux->Duqueco220 [179/325]\n",
      "Procesando datos de Charrua220->EntreRios220 [180/325]\n",
      "Procesando datos de Charrua220->Hualpen220 [181/325]\n",
      "Procesando datos de Charrua220->Lagunillas220 [182/325]\n",
      "Procesando datos de Charrua220Aux->Mulchen220 [183/325]\n",
      "Procesando datos de Charrua220->Ralco220 [184/325]\n",
      "Procesando datos de Charrua500->Ancoa500AuxS [185/325]\n",
      "Procesando datos de Chena110->LoEspejo110 [186/325]\n",
      "Procesando datos de Chena220->Chena110 [187/325]\n",
      "Procesando datos de Chillan154->SantaElvira066 [188/325]\n",
      "Procesando datos de Chiloe110->Degan110 [189/325]\n",
      "Procesando datos de Chiloe110->Pid-Pid110 [190/325]\n",
      "Procesando datos de Chiloe220->Chiloe110 [191/325]\n",
      "Procesando datos de Cholguan220->Charrua220 [192/325]\n",
      "Procesando datos de Cipreses154->Itahue154 [193/325]\n",
      "Procesando datos de Ciruelos220->Pichirropulli220Aux [194/325]\n",
      "Procesando datos de Ciruelos220->Valdivia220 [195/325]\n",
      "Procesando datos de CNavia110->Batuco110 [196/325]\n",
      "Procesando datos de CNavia110->Batuco110_I [197/325]\n",
      "Procesando datos de CNavia110->Chena110 [198/325]\n",
      "Procesando datos de CNavia110->LVegas110_exp [199/325]\n",
      "Procesando datos de CNavia220_Aux_D->Polpaico220 [200/325]\n",
      "Procesando datos de CNavia220->Chena220 [201/325]\n",
      "Procesando datos de CNavia220->CNavia110 [202/325]\n",
      "Procesando datos de CNavia220->CNavia220_Aux_D [203/325]\n",
      "Procesando datos de Colbun220->Ancoa220 [204/325]\n",
      "Procesando datos de Colbun220->PNegro220 [205/325]\n",
      "Procesando datos de Conce154->Conce066 [206/325]\n",
      "Procesando datos de Conce154->SVicente154 [207/325]\n",
      "Procesando datos de Coronel066->Guindo066 [208/325]\n",
      "Procesando datos de Coronel154->Coronel066 [209/325]\n",
      "Procesando datos de Coronel154->Horcones066 [210/325]\n",
      "Procesando datos de Duqueco220->Temuco220 [211/325]\n",
      "Procesando datos de ElSalto110->SCristobal110 [212/325]\n",
      "Procesando datos de EntreRios500->Ancoa500AuxS [213/325]\n",
      "Procesando datos de EntreRios500->Charrua500 [214/325]\n",
      "Procesando datos de EntreRios500->EntreRios220 [215/325]\n",
      "Procesando datos de Florida110->Almendros110 [216/325]\n",
      "Procesando datos de Florida110->StaRosa110 [217/325]\n",
      "Procesando datos de Fopaco154->Lagunillas154 [218/325]\n",
      "Procesando datos de Guindo066->Concepcio066 [219/325]\n",
      "Procesando datos de Guindo220->Guindo066 [220/325]\n",
      "Procesando datos de Guindo220->Hualpen220 [221/325]\n",
      "Procesando datos de Hualpen154->Mapal154 [222/325]\n",
      "Procesando datos de Hualpen220->Hualpen154 [223/325]\n",
      "Procesando datos de Itahue154->Maule154 [224/325]\n",
      "Procesando datos de Itahue154->Teno154 [225/325]\n",
      "Procesando datos de Itahue220->Maule220 [226/325]\n",
      "Procesando datos de Lagunillas154->Coronel154 [227/325]\n",
      "Procesando datos de Lagunilla220->Guindo220 [228/325]\n",
      "Procesando datos de Lagunillas220->Lagunillas154 [229/325]\n",
      "Procesando datos de Linares154->SJavier066 [230/325]\n",
      "Procesando datos de LoAguirre220->CNavia220 [231/325]\n",
      "Procesando datos de LoAguirre500->AJahuel500 [232/325]\n",
      "Procesando datos de LoAguirre500->LoAguirre220 [233/325]\n",
      "Procesando datos de LoAguirre500->LoAguirre220_2 [234/325]\n",
      "Procesando datos de LoAguirre500->Polpaico500 [235/325]\n",
      "Procesando datos de LoEspejo110->Ochagavia110 [236/325]\n",
      "Procesando datos de Malloa154->Tinguiririca154 [237/325]\n",
      "Procesando datos de Mapal154->Fopaco154 [238/325]\n",
      "Procesando datos de Maule154->Linares154 [239/325]\n",
      "Procesando datos de Maule154->SMiguel066 [240/325]\n",
      "Procesando datos de Mulchen220->Cautin220 [241/325]\n",
      "Procesando datos de Nogales220->Polpaico220 [242/325]\n",
      "Procesando datos de Nogales220->Quillota220 [243/325]\n",
      "Procesando datos de Nogales220->Ventanas220 [244/325]\n",
      "Procesando datos de Ochagavia110->Florida110 [245/325]\n",
      "Procesando datos de Pachacama110->LVegas110 [246/325]\n",
      "Procesando datos de Paine154->Tuniche154_I [247/325]\n",
      "Procesando datos de Pangue220->Cholguan220 [248/325]\n",
      "Procesando datos de Pangue220->Trupan220 [249/325]\n",
      "Procesando datos de Parral154->Linares154 [250/325]\n",
      "Procesando datos de Pehuenche220->Ancoa220 [251/325]\n",
      "Procesando datos de Petroquim154->Hualpen154 [252/325]\n",
      "Procesando datos de Pichirropulli220->Tineo220 [253/325]\n",
      "Procesando datos de Pid-Pid110->Chonchi110 [254/325]\n",
      "Procesando datos de Pillanlelbun066->Lautaro066 [255/325]\n",
      "Procesando datos de PMontt220->Chiloe220 [256/325]\n",
      "Procesando datos de Tineo220->Chiloe220 [257/325]\n",
      "Procesando datos de PMontt220->Molinos110 [258/325]\n",
      "Procesando datos de PNegro220->Candela220 [259/325]\n",
      "Procesando datos de PNegro220->Tinguiririca220 [260/325]\n",
      "Procesando datos de Polpaico220->ElSalto110 [261/325]\n",
      "Procesando datos de Polpaico500->Polpaico220 [262/325]\n",
      "Procesando datos de PPeuco110->LVegas110 [263/325]\n",
      "Procesando datos de PPeuco110->LVegas110_I [264/325]\n",
      "Procesando datos de Prrahue220->Rahue220 [265/325]\n",
      "Procesando datos de Prropulli220AuxS->Prrahue220 [266/325]\n",
      "Procesando datos de Prropulli220AuxS->Rahue220 [267/325]\n",
      "Procesando datos de Quillota110->Mirafl110 [268/325]\n",
      "Procesando datos de Quillota110->Pachacam110 [269/325]\n",
      "Procesando datos de Quillota220->Polpaico220 [270/325]\n",
      "Procesando datos de Quillota220->Quillota110 [271/325]\n",
      "Procesando datos de Quintero220->SanLuis220 [272/325]\n",
      "Procesando datos de Rahue220->Tineo220 [273/325]\n",
      "Procesando datos de Tineo220->PMontt220 [274/325]\n",
      "Procesando datos de Rancagua154->Tuniche154_I [275/325]\n",
      "Procesando datos de Rancagua154->Tuniche154_II [276/325]\n",
      "Procesando datos de Rapel220->AMelipill220 [277/325]\n",
      "Procesando datos de Renca110->CNavia110 [278/325]\n",
      "Procesando datos de RioTolten220->Ciruelos220 [279/325]\n",
      "Procesando datos de Rucue220->Charrua220 [280/325]\n",
      "Procesando datos de SanLuis220->ASanta220 [281/325]\n",
      "Procesando datos de SanLuis220->Quillota220 [282/325]\n",
      "Procesando datos de SantaMaria220->Charrua220 [283/325]\n",
      "Procesando datos de SantaMarta220->Chena220 [284/325]\n",
      "Procesando datos de Sauzal110_2->Sauzal154 [285/325]\n",
      "Procesando datos de Sauzal154->Rancagua154 [286/325]\n",
      "Procesando datos de SCristobal110->CNavia110 [287/325]\n",
      "Procesando datos de SFcoMost066->Paine154 [288/325]\n",
      "Procesando datos de SJavier66->Constituci66 [289/325]\n",
      "Procesando datos de SMiguel66->Talca66 [290/325]\n",
      "Procesando datos de StaRosa110->AJahuel110 [291/325]\n",
      "Procesando datos de SVicente154->Hualpen154 [292/325]\n",
      "Procesando datos de SVicente154->Petroq154 [293/325]\n",
      "Procesando datos de Talca66->SJavier66 [294/325]\n",
      "Procesando datos de Temuco220->Cautin220 [295/325]\n",
      "Procesando datos de Temuco220->Temuco66 [296/325]\n",
      "Procesando datos de Temuco66->Pillanlelbun66 [297/325]\n",
      "Procesando datos de Tilcoco154->Malloa154 [298/325]\n",
      "Procesando datos de Tilcoco154->PCortes154 [299/325]\n",
      "Procesando datos de Tinguiririca154->Itahue154 [300/325]\n",
      "Procesando datos de Tinguiririca154->Teno154 [301/325]\n",
      "Procesando datos de Tinguiririca220->Tinguiririca154 [302/325]\n",
      "Procesando datos de Torquemada110->Mirafl110 [303/325]\n",
      "Procesando datos de Trupan220->Charrua220 [304/325]\n",
      "Procesando datos de Tuniche_1->PCortes154 [305/325]\n",
      "Procesando datos de Tuniche_1->Tinguiririca154 [306/325]\n",
      "Procesando datos de Tuniche_2->PCortes154 [307/325]\n",
      "Procesando datos de Valdivia220->Pichirropulli220Aux [308/325]\n",
      "Procesando datos de Ventanas110->Mirafl110 [309/325]\n",
      "Procesando datos de Ventanas110->Quillota110 [310/325]\n",
      "Procesando datos de Ventanas110->Torquemada110 [311/325]\n",
      "Procesando datos de Ventanas220->Ventanas110 [312/325]\n",
      "Procesando datos de PAzucar220->PAzucar220_aux [313/325]\n",
      "Procesando datos de PAzucar220->PAzucar220_aux2 [314/325]\n",
      "Procesando datos de Nogales220aux->Nogales220 [315/325]\n",
      "Procesando datos de Ancoa500AuxS->Ancoa500 [316/325]\n",
      "Procesando datos de Pichirropulli220->Pichirropulli220AuxS [317/325]\n",
      "Procesando datos de Pichirropulli220Aux->Pichirropulli220 [318/325]\n",
      "Procesando datos de Charrua220->Charrua220Aux [319/325]\n",
      "Procesando datos de ASanta220->AMelipilla220 [320/325]\n",
      "Procesando datos de Itahue154->NvaNirivilo220 [321/325]\n",
      "Procesando datos de NvaNirivilo220->NvaCauquenes220 [322/325]\n",
      "Procesando datos de NvaCauquenes220->Lagunillas220 [323/325]\n",
      "Procesando datos de NvaNirivilo220->Constitucion066 [324/325]\n",
      "Procesando datos de NvaCauquenes220->Parral154 [325/325]\n"
     ]
    }
   ],
   "source": [
    "def percentilFL():\n",
    "    datos_lineas=plplin[['id','Hidro', 'time', 'LinName', 'LinFluP', 'capacity']]\n",
    "    lista_lineas = datos_lineas.LinName.unique()\n",
    "    n_lineas = len(lista_lineas)\n",
    "    i=1\n",
    "    for linea in lista_lineas:\n",
    "        print(f'Procesando datos de {linea} [{i}/{n_lineas}]')\n",
    "        data_lineaTx = datos_lineas.loc[(datos_lineas.LinName == linea)]\n",
    "        idlin=data_lineaTx['id'].unique()[0]\n",
    "        data_lineaTx = data_lineaTx[~(data_lineaTx['Hidro'] == 'MEDIA')]\n",
    "        fluMax = data_lineaTx[['time','capacity']]\n",
    "        xy =-fluMax.groupby(['time']).max()\n",
    "        data_lineaTx = data_lineaTx.groupby(['time']).agg(perc0=('LinFluP', lambda x: x.quantile(0.0)),\n",
    "                                                                perc20=(\n",
    "                                                                    'LinFluP', lambda x: x.quantile(0.2)),\n",
    "                                                                perc80=(\n",
    "                                                                    'LinFluP', lambda x: x.quantile(0.8)),\n",
    "                                                                perc100=('LinFluP', lambda x: x.quantile(1)))\n",
    "\n",
    "        data_lineaTx['Min'] = xy\n",
    "        data_lineaTx['Max'] = -xy\n",
    "        i = i+1\n",
    "        data_lineaTx.reset_index(inplace=True)\n",
    "        data_lineaTx = data_lineaTx.assign(id=idlin)\n",
    "        data_lineaTx = data_lineaTx.assign(LinName = linea)\n",
    "        data_lineaTx.to_json(line_flow_percentil_path+f\"/line_{idlin}.json\",orient='records')\n",
    "\n",
    "percentilFL()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando scenarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidro</th>\n",
       "      <th>time</th>\n",
       "      <th>TipoEtapa</th>\n",
       "      <th>id</th>\n",
       "      <th>BarName</th>\n",
       "      <th>CMgBar</th>\n",
       "      <th>DemBarP</th>\n",
       "      <th>DemBarE</th>\n",
       "      <th>PerBarP</th>\n",
       "      <th>PerBarE</th>\n",
       "      <th>BarRetP</th>\n",
       "      <th>BarRetE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sim1</td>\n",
       "      <td>1</td>\n",
       "      <td>5 Bloques</td>\n",
       "      <td>1</td>\n",
       "      <td>AltoNorte110</td>\n",
       "      <td>178.58</td>\n",
       "      <td>46.04</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.002</td>\n",
       "      <td>8221.89</td>\n",
       "      <td>172.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hidro  time     TipoEtapa  id       BarName  CMgBar  DemBarP  DemBarE  \\\n",
       "0  Sim1     1  5 Bloques      1  AltoNorte110  178.58    46.04    0.967   \n",
       "\n",
       "   PerBarP  PerBarE  BarRetP  BarRetE  \n",
       "0    0.101    0.002  8221.89   172.66  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plpbar.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666666666666667% Completado\n",
      "13.333333333333334% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.666666666666668% Completado\n",
      "33.33333333333333% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.0% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.666666666666664% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.333333333333336% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0% Completado\n",
      "66.66666666666666% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.33333333333333% Completado\n",
      "80.0% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.66666666666667% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.33333333333333% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% Completado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_15012\\880538489.py:41: RuntimeWarning: coroutine 'busscenariofunction' was never awaited\n",
      "  busscenariofunction(dfbuslist,busscenariolist[hidronum])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# Bus contiene:\n",
    "'''\n",
    "\t\t(*) id <int>: identificador de la barra \n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) name <str>: nombre de la barra\n",
    "\t\tmarginal_cost <float>: costo marginal, genera el gráfico de costo\n",
    "\t\t\t\t\t[USD/MWh]\n",
    "\t\tDemBarE <float>: construye el gráfico de demanda de Energía [MWh]\n",
    "\t\tDemBarP <float>: construye el gráfico de demanda de Potencia [MW]\n",
    "\t\tValue <float>: mismo valor que marginal_cost [MWh]\n",
    "'''\n",
    "\n",
    "def busscenariofunction(dfbusauxlist,pathbus):\n",
    "\tfor x in range(nbus): # Para cada barra\n",
    "\n",
    "\t\tbus_sc_1filas_aux=[]\n",
    "\t\tfor y in range(1,time+1): # Para cada bloque de tiempo, se agrega un estado de la barra x\n",
    "\t\t\taux=[]\n",
    "\t\t\t\n",
    "\t\t\tidbus=indexbus['id'][x]\n",
    "\t\t\taux.append(idbus)\n",
    "\t\t\taux.append(y)\n",
    "\t\t\taux.append(indexbus['BarName'][x])\n",
    "\t\t\taux.append(dfbusauxlist[x]['CMgBar'][y-1])\n",
    "\t\t\taux.append(aux[-1])\n",
    "\t\t\taux.append(dfbusauxlist[x]['DemBarE'][y-1])\n",
    "\t\t\taux.append(dfbusauxlist[x]['DemBarP'][y-1])\n",
    "\t\t\taux.append(dfbusauxlist[x]['BarRetP'][y-1])\n",
    "\t\t\tbus_sc_1filas_aux.append(aux)\n",
    "\t\tbus_sc_1_aux=pd.DataFrame(bus_sc_1filas_aux,columns=['id','time','name','marginal_cost','value','DemBarE','DemBarP','BarRetP'])\n",
    "\t\tbus_sc_1_aux.to_json(pathbus+f\"/bus_{idbus}.json\",orient='records')\n",
    "\n",
    "for hidronum,hidroname in enumerate(hidrolist):\n",
    "\t\n",
    "\tdfbussauxx=plpbar.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "\tdfbuslist=[]\n",
    "\tfor x in lbus:\n",
    "\t\tidaux=x\n",
    "\t\tdfbuslist.append(dfbussauxx[dfbussauxx.id==idaux].reset_index(drop=True))\n",
    "\tprint(f\"{((hidronum+1)/len(hidrolist))*100}% Completado\")\n",
    "\tbusscenariofunction(dfbuslist,busscenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sim1', 'Sim2', 'Sim3', 'Sim4', 'Sim5', 'Sim6', 'Sim7', 'Sim8',\n",
       "       'Sim9', 'Sim10', 'Sim11', 'Sim12', 'Sim13', 'Sim14', 'MEDIA'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidrolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidro</th>\n",
       "      <th>time</th>\n",
       "      <th>TipoEtapa</th>\n",
       "      <th>id</th>\n",
       "      <th>CenName</th>\n",
       "      <th>tipo</th>\n",
       "      <th>bus_id</th>\n",
       "      <th>BarName</th>\n",
       "      <th>CenQgen</th>\n",
       "      <th>CenPgen</th>\n",
       "      <th>CenCVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sim1</td>\n",
       "      <td>1</td>\n",
       "      <td>5 Bloques</td>\n",
       "      <td>2</td>\n",
       "      <td>CIPRESES</td>\n",
       "      <td>hidraulica_embalse</td>\n",
       "      <td>123</td>\n",
       "      <td>Cipreses154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sim1</td>\n",
       "      <td>2</td>\n",
       "      <td>5 Bloques</td>\n",
       "      <td>2</td>\n",
       "      <td>CIPRESES</td>\n",
       "      <td>hidraulica_embalse</td>\n",
       "      <td>123</td>\n",
       "      <td>Cipreses154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sim1</td>\n",
       "      <td>3</td>\n",
       "      <td>5 Bloques</td>\n",
       "      <td>2</td>\n",
       "      <td>CIPRESES</td>\n",
       "      <td>hidraulica_embalse</td>\n",
       "      <td>123</td>\n",
       "      <td>Cipreses154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sim1</td>\n",
       "      <td>4</td>\n",
       "      <td>5 Bloques</td>\n",
       "      <td>2</td>\n",
       "      <td>CIPRESES</td>\n",
       "      <td>hidraulica_embalse</td>\n",
       "      <td>123</td>\n",
       "      <td>Cipreses154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sim1</td>\n",
       "      <td>5</td>\n",
       "      <td>5 Bloques</td>\n",
       "      <td>2</td>\n",
       "      <td>CIPRESES</td>\n",
       "      <td>hidraulica_embalse</td>\n",
       "      <td>123</td>\n",
       "      <td>Cipreses154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hidro  time     TipoEtapa  id   CenName                tipo  bus_id  \\\n",
       "0  Sim1     1  5 Bloques      2  CIPRESES  hidraulica_embalse     123   \n",
       "1  Sim1     2  5 Bloques      2  CIPRESES  hidraulica_embalse     123   \n",
       "2  Sim1     3  5 Bloques      2  CIPRESES  hidraulica_embalse     123   \n",
       "3  Sim1     4  5 Bloques      2  CIPRESES  hidraulica_embalse     123   \n",
       "4  Sim1     5  5 Bloques      2  CIPRESES  hidraulica_embalse     123   \n",
       "\n",
       "                                            BarName  CenQgen  CenPgen  CenCVar  \n",
       "0  Cipreses154                                           0.0      0.0      0.0  \n",
       "1  Cipreses154                                           0.0      0.0      0.0  \n",
       "2  Cipreses154                                           0.0      0.0      0.0  \n",
       "3  Cipreses154                                           0.0      0.0      0.0  \n",
       "4  Cipreses154                                           0.0      0.0      0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plpcen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PLP20230104/Scenarios/1/Centrals',\n",
       " 'PLP20230104/Scenarios/2/Centrals',\n",
       " 'PLP20230104/Scenarios/3/Centrals',\n",
       " 'PLP20230104/Scenarios/4/Centrals',\n",
       " 'PLP20230104/Scenarios/5/Centrals',\n",
       " 'PLP20230104/Scenarios/6/Centrals',\n",
       " 'PLP20230104/Scenarios/7/Centrals',\n",
       " 'PLP20230104/Scenarios/8/Centrals',\n",
       " 'PLP20230104/Scenarios/9/Centrals',\n",
       " 'PLP20230104/Scenarios/10/Centrals',\n",
       " 'PLP20230104/Scenarios/11/Centrals',\n",
       " 'PLP20230104/Scenarios/12/Centrals',\n",
       " 'PLP20230104/Scenarios/13/Centrals',\n",
       " 'PLP20230104/Scenarios/14/Centrals',\n",
       " 'PLP20230104/Scenarios/15/Centrals']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centralscenariolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666666666666667% Completado\n",
      "13.333333333333334% Completado\n",
      "20.0% Completado\n",
      "26.666666666666668% Completado\n",
      "33.33333333333333% Completado\n",
      "40.0% Completado\n",
      "46.666666666666664% Completado\n",
      "53.333333333333336% Completado\n",
      "60.0% Completado\n",
      "66.66666666666666% Completado\n",
      "73.33333333333333% Completado\n",
      "80.0% Completado\n",
      "86.66666666666667% Completado\n",
      "93.33333333333333% Completado\n",
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "# Centrals contiene:\n",
    "'''\n",
    "\t\t(*) id <int>: identificador del generador\n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) bus_id <int>: identificador de la barra a la que se conecta\n",
    "\t\t(*) name <str>: nombre del generador\n",
    "\t\tCenPgen <float>: energía generada en el instante time [MW]\n",
    "\t\tvalue <float>: mismo valor que CenPgen [MW]\n",
    "\t\t(?) CenCVar <unknown>: parámetro no identificado\n",
    "\t\t(?) CenQgen <unknown>: parámetro no identificado\n",
    "        \n",
    "'''\n",
    "def centralscenariofunction(dfcenauxlist,cenpath):\n",
    "\t\n",
    "\tfor x in range(ngen): # Para cada generador (central)\n",
    "\t\tif indexcen['bus_id'][x]==0 or np.isnan(indexcen['bus_id'][x]): # No existe la barra 0, por lo que no se consideran dichos generadores\n",
    "\t\t\tpass\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tcentral_sc_1filas_aux=[]\n",
    "\t\t\tfor y in range(1,time+1): # Para cada bloque de tiempo, se agrega un estado del generador x\n",
    "\t\t\t\taux=[]\n",
    "\t\t\t\taux.append(indexcen['id'][x])\n",
    "\t\t\t\taux.append(y)\n",
    "\t\t\t\taux.append(int(indexcen['bus_id'][x]))\n",
    "\t\t\t\taux.append(indexcen['CenName'][x])\n",
    "\t\t\t\tif len(dfcenauxlist[x])==0:\n",
    "\t\t\t\t\tfor i in range(4):\n",
    "\t\t\t\t\t\taux.append(0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\taux.append(dfcenauxlist[x]['CenPgen'][y-1])\n",
    "\t\t\t\t\taux.append(aux[-1])\n",
    "\t\t\t\t\taux.append(dfcenauxlist[x]['CenCVar'][y-1])\n",
    "\t\t\t\t\taux.append(dfcenauxlist[x]['CenQgen'][y-1])\n",
    "\t\t\t\tcentral_sc_1filas_aux.append(aux)\n",
    "\t\t\tcentral_sc_1_aux=pd.DataFrame(central_sc_1filas_aux,columns=['id','time','bus_id','name','CenPgen','value','CenCVar','CenQgen'])\n",
    "\t\t\tcentral_sc_1_aux.to_json(cenpath+f\"/central_{indexcen['id'][x]}.json\",orient='records')\n",
    "\n",
    "for hidronum,hidroname in enumerate(hidrolist):\n",
    "\t\n",
    "\tdfcensauxx=plpcen.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "\tdfcenlist=[]\n",
    "\tfor x in range(ngen):\n",
    "\t\t\tidaux=indexcen['id'][x]\n",
    "\t\t\tdfcenlist.append(dfcensauxx[dfcensauxx.id==idaux].reset_index(drop=True))\n",
    "\tprint(f\"{((hidronum+1)/len(hidrolist))*100}% Completado\")\n",
    "\tcentralscenariofunction(dfcenlist,centralscenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666666666666667% Completado\n",
      "13.333333333333334% Completado\n",
      "20.0% Completado\n",
      "26.666666666666668% Completado\n",
      "33.33333333333333% Completado\n",
      "40.0% Completado\n",
      "46.666666666666664% Completado\n",
      "53.333333333333336% Completado\n",
      "60.0% Completado\n",
      "66.66666666666666% Completado\n",
      "73.33333333333333% Completado\n",
      "80.0% Completado\n",
      "86.66666666666667% Completado\n",
      "93.33333333333333% Completado\n",
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "        (*) id <int>: identificador de la linea \n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) bus_a <int>: identificador de la barra de origen\n",
    "\t\t(*) bus_b <int>: identificador de la barra de destino\n",
    "\t\tflow <float>: flujo en el instante time [MW]\n",
    "\t\tvalue <float>: mismo valor que flow [MW]\n",
    "        \n",
    "'''\n",
    "\n",
    "def linescenariofunction(dflinelist,linpath):\n",
    "\tfor x in range(nlin): # Para cada linea\n",
    "\t\tline_sc_1filas_aux=[]\n",
    "\t\tfor y in range(1,time+1): # Para cada bloque de tiempo, se agrega un estado de la linea x\n",
    "\t\t\taux=[]\n",
    "\t\t\tidaux=linesfinal['id'][x]\n",
    "\t\t\tbus_a_id = linesfinal['bus_a'][x]\n",
    "\t\t\tbus_b_id = linesfinal['bus_b'][x]\n",
    "\t\t\tname = f\"{indexbus.BarName[bus_a_id - 1]}->{indexbus.BarName[bus_b_id - 1]}\"\n",
    "\t\t\taux.append(idaux)\n",
    "\t\t\taux.append(y)\n",
    "\t\t\taux.append(name)\n",
    "\t\t\taux.append(bus_a_id)\n",
    "\t\t\taux.append(bus_b_id)\n",
    "\t\t\taux.append(dflinelist[x]['LinFluP'][y-1])\n",
    "\t\t\taux.append(aux[-1])\n",
    "\t\t\taux.append(dflinelist[x]['capacity'][y-1])\n",
    "\n",
    "\t\t\t\n",
    "\t\t\tline_sc_1filas_aux.append(aux)\n",
    "\t\tline_sc_1_aux=pd.DataFrame(line_sc_1filas_aux,columns=['id','time',\"name\",'bus_a','bus_b','flow','value','capacity'])\n",
    "\t\tline_sc_1_aux.to_json(linpath+f\"/line_{idaux}.json\",orient='records')\n",
    "\n",
    "for hidronum,hidroname in enumerate(hidrolist):\n",
    "\t\n",
    "\tdflinesaux=plplin.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "\tdflinelist=[]\n",
    "\tfor x in range(nlin):\n",
    "\t\tidaux=linesfinal['id'][x]\n",
    "\t\tdflinelist.append(dflinesaux[dflinesaux.id==idaux].reset_index(drop=True))\n",
    "\tprint(f\"{((hidronum+1)/len(hidrolist))*100}% Completado\")\n",
    "\tlinescenariofunction(dflinelist,linescenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666666666666667% Completado\n",
      "13.333333333333334% Completado\n",
      "20.0% Completado\n",
      "26.666666666666668% Completado\n",
      "33.33333333333333% Completado\n",
      "40.0% Completado\n",
      "46.666666666666664% Completado\n",
      "53.333333333333336% Completado\n",
      "60.0% Completado\n",
      "66.66666666666666% Completado\n",
      "73.33333333333333% Completado\n",
      "80.0% Completado\n",
      "86.66666666666667% Completado\n",
      "93.33333333333333% Completado\n",
      "100.0% Completado\n"
     ]
    }
   ],
   "source": [
    "# Resevoirs contiene:\n",
    "'''\n",
    "\t\t(*) time <int>: instante de registro\n",
    "\t\t(*) id <int>: identificador del embalse\n",
    "\t\t(*) junction_id <int>: identificador del canal al que se conecta\n",
    "\t\t(*) name <str>: nombre del embalse\n",
    "\t\tlevel <float>: nivel en el instante time\n",
    "\t\tvalue <float>: mismo valor que level\n",
    "'''\n",
    "\n",
    "def resscenariofunction(dfreslist,respath):\n",
    "\tfor x in range(nres):\n",
    "\t\tres_sc_filas_aux=[]\n",
    "\t\tidaux=indexres['id'][x]\n",
    "\t\tname=indexres['EmbName'][x]\n",
    "\t\tjunction_id = junctionsinfo[junctionsinfo['CenName']==name]['id'].values[0]\n",
    "\t\tfor y in range(1,time+1): # Para cada bloque de tiempo, se agrega un estado del embalse x\n",
    "\t\t\taux=[]\n",
    "\t\t\taux.append(y)\n",
    "\t\t\taux.append(idaux)\n",
    "\t\t\taux.append(junction_id)\n",
    "\t\t\taux.append(name)\n",
    "\t\t\taux.append((dfreslist[x]['EmbFac'][y-1]*dfreslist[x]['EmbVfin'][y-1])/1000000)\n",
    "\t\t\taux.append(aux[-1])\n",
    "\t\t\tres_sc_filas_aux.append(aux)\n",
    "\n",
    "\t\tres_sc_1_aux=pd.DataFrame(res_sc_filas_aux,columns=['time','id','junction_id','name','level','value'])\n",
    "\t\tres_sc_1_aux.to_json(respath+f\"/reservoir_{idaux}.json\",orient='records')\n",
    "\n",
    "for hidronum,hidroname in enumerate(hidrolist):\n",
    "\tdfresaux=reservoirs.query(f\"(Hidro=='{hidroname}')\").reset_index()\n",
    "\tdfreslist=[]\n",
    "\tfor x in range(nres):\n",
    "\t\tidaux=indexres['id'][x]\n",
    "\t\tdfreslist.append(dfresaux[dfresaux.id==idaux].reset_index(drop=True))\n",
    "\tprint(f\"{((hidronum+1)/len(hidrolist))*100}% Completado\")\n",
    "\tresscenariofunction(dfreslist,reservoirscenariolist[hidronum])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubibar[['latUTM','lonUTM']]=ubibar.apply(lambda row: valorXY(row['latitud'],row['longitud'],scale=0.001),axis=1,result_type='expand')\n",
    "dirdfbus=ubibar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus electric contiene:\n",
    "\n",
    "'''   \n",
    "\t\t(*) id <int>: identificador de la barra\n",
    "\t\t(*) name <str>: nombre de la barra\n",
    "\t\tlongitude <float>\n",
    "\t\tlatitude <float>\n",
    "\t\tactive <int>: indica si la barra está activa\n",
    "'''\n",
    "\n",
    "escalador = 1\n",
    "auxiliar=[]\n",
    "buselectricfilas_aux=[]\n",
    "for x in range(nbus): # Para cada barra (bus)\n",
    "\tif dirdfbus['BarName'].isin([indexbus['BarName'][x]]).tolist().count(True)>0:\n",
    "\t\t# latitud=float(dirdfbus[dirdfbus['BarName']==indexbus['BarName'][x]]['latUTM'].values[0])\n",
    "\t\t# longitud=float(dirdfbus[dirdfbus['BarName']==indexbus['BarName'][x]]['lonUTM'].values[0])\n",
    "\t\tlatitud=float(dirdfbus[dirdfbus['BarName']==indexbus['BarName'][x]]['latitud'].values[0])*escalador\n",
    "\t\tlongitud=float(dirdfbus[dirdfbus['BarName']==indexbus['BarName'][x]]['longitud'].values[0])*escalador\n",
    "\telse:\n",
    "\t\tauxiliar.append(indexbus['BarName'][x])\n",
    "\t\tlatitud,longitud=aleatory_direction()\n",
    "\t\t# latitud,longitud=valorXY(latitud,longitud,scale=0.00001)\n",
    "\n",
    "\taux=[]\n",
    "\taux.append(indexbus['id'][x])\n",
    "\taux.append(indexbus['BarName'][x])\n",
    "\taux.append(longitud)\n",
    "\taux.append(latitud)\n",
    "\taux.append(1)\n",
    "\tbuselectricfilas_aux.append(aux)\n",
    "\n",
    "buselectric=pd.DataFrame(buselectricfilas_aux,columns=['id','name','longitude','latitude','active'])\n",
    "\n",
    "buselectric.to_json(electricTopology+\"/bus.json\",orient='records')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### centrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centrals electric contiene:\n",
    "\n",
    "'''   \n",
    "        (*) id <int>: identificador del generador\n",
    "\t\t(*) bus_id <int>: id de la barra conectada al generador\n",
    "\t\t(*) name <str>: nombre del generador\n",
    "\t\tactive <int>: indica si el generador está activo\n",
    "\t\tcapacity <float>: capacidad del generador [MW]\n",
    "\t\tmin_power <float>: generación mínima [MW]\n",
    "\t\tmax_power <float>: generación máxima [MW]\n",
    "\t\ttype <str>: tipo de generador\n",
    "\t\tlongitude <float>\n",
    "\t\tlatitude <float>\n",
    "\t\t(?) effinciency <float>: Rendimiento [MWh/m3s]\n",
    "\t\t(?) flow <float>: parámetro no identificado\n",
    "\t\t(?) rmin <float>: parámetro no identificado\n",
    "\t\t(?) rmax <float>: parámetro no identificado\n",
    "\t\t(?) cvar <float>: Costo Variable\n",
    "\t\t(?) cvnc <unknown>: parámetro no identificado\n",
    "\t\t(?) cvc <unknown>: parámetro no identificado\n",
    "\t\t(?) entry_date <unknown>: parámetro no identificado\n",
    "\n",
    "'''\n",
    "\n",
    "centralselectricfilas_aux=[]\n",
    "for x in range(ngen): # Para cada generador (central)\n",
    "\tif indexcen['bus_id'][x]==0 or np.isnan(indexcen['bus_id'][x]): # No existe la barra 0, por lo que no se consideran dichos generadores\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tlatitud,longitud=None,None\n",
    "\t\taux=[]\n",
    "\t\taux.append(indexcen['id'][x])\n",
    "\t\taux.append(int(indexcen['bus_id'][x]))\n",
    "\t\taux.append(indexcen['CenName'][x])\n",
    "\t\taux.append(1)\n",
    "\t\t# capacidad\n",
    "\t\taux.append(0)\n",
    "\t\taux.append(centralsinfo[centralsinfo['CenName']==indexcen['CenName'][x]]['min_power'])\n",
    "\t\taux.append(centralsinfo[centralsinfo['CenName']==indexcen['CenName'][x]]['max_power'])\n",
    "\t\ttipo=typecentrals[typecentrals['CenName']==indexcen['CenName'][x]]['cen_type'].values\n",
    "\t\tif len(tipo)>0:\n",
    "\t\t\taux.append(tipo[0])\n",
    "\t\telse:\n",
    "\t\t\taux.append(None)\n",
    "\t\taux.append(longitud)\n",
    "\t\taux.append(latitud)\n",
    "\t\taux.append(centralsinfo[centralsinfo['CenName']==indexcen['CenName'][x]]['effinciency'])\n",
    "\t\tfor x in range(7):\n",
    "\t\t\taux.append(0)\n",
    "\t\tcentralselectricfilas_aux.append(aux)\n",
    "\n",
    "centralelectric=pd.DataFrame(centralselectricfilas_aux,columns=['id','bus_id','name','active','capacity','min_power','max_power','type','longitude','latitude','efficiency','flow','rmin','rmax','cvar',\n",
    "'cvnc','cvc','entry_date'])\n",
    "\n",
    "centralelectric.to_json(electricTopology+\"/centrals.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines electric tiene:\n",
    "'''  \n",
    "        (*) id <int>: identificador de la línea\n",
    "\t\t(*) bus_a <int>: id de la barra origen\n",
    "\t\t(*) bus_b <int>: id de la barra destino\n",
    "\t\tactive <int>: indica si la línea está activa\n",
    "\t\tcapacity <float>: capacidad máxima de la línea [MW]  ->\n",
    "\t\tmax_flow_a_b <float>: flujo máximo en dirección\n",
    "\t\t\t\t\tdispuesta [MW]\n",
    "\t\tmax_flow_b_a <float>: flujo máximo en dirección\n",
    "\t\t\t\t\tcontraria [MW]\n",
    "\t\tvoltage <float>: voltaje de la línea [kV]\n",
    "\t\tr <float>: resistencia de la línea [Ω]\n",
    "\t\tx <float>: reactancia de la línea [Ω]\n",
    "\t\t(? )segments <int>: parámetro no identificado\n",
    "\t\t(?) entry_date <unknown>: parámetro no identificado\n",
    "\t\t(?) exit_date <unknown>: parámetro no identificado\n",
    "\n",
    "'''\n",
    "\n",
    "lineselectricfilas_aux=[]\n",
    "for x in range(nlin): # Para cada linea\n",
    "\taux=[]\n",
    "\tbus_a_id = linesfinal['bus_a'][x]\n",
    "\tbus_b_id = linesfinal['bus_b'][x]\n",
    "\tname = f\"{indexbus.BarName[bus_a_id - 1]}->{indexbus.BarName[bus_b_id - 1]}\"\n",
    "\taux.append(linesfinal['id'][x])\n",
    "\taux.append(name)\n",
    "\taux.append(bus_a_id)\n",
    "\taux.append(bus_b_id)\n",
    "\taux.append(1)\n",
    "\t# capacidad\n",
    "\taux.append(0)\n",
    "\taux.append(linesfinal['max_flow_a_b'][x])\n",
    "\taux.append(linesfinal['max_flow_b_a'][x])\n",
    "\taux.append(linesfinal['voltage'][x])\n",
    "\taux.append(linesfinal['r'][x])\n",
    "\taux.append(linesfinal['x'][x])\n",
    "\taux.append(linesfinal['segments'][x])\n",
    "\taux.append(None)\n",
    "\taux.append(None)\n",
    "\t\n",
    "\tlineselectricfilas_aux.append(aux)\n",
    "\n",
    "lineelectric=pd.DataFrame(lineselectricfilas_aux,columns=['id','name','bus_a','bus_b','active','capacity','max_flow_a_b','max_flow_b_a','voltage','r','x','segments','entry_date','exit_date'])\n",
    "\n",
    "lineelectric.to_json(electricTopology+\"/lines.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   \n",
    "        (*) id <int>: identificador del embalse\n",
    "\t\t(*) junction_id <int>: id del embalse relacionada (mismo valor id)\n",
    "\t\t(*) name <str>: nombre del embalse\n",
    "\t\t(*) type <str>: tipo de embalse\n",
    "\t\tmin_vol <float>: volumen mínimo del embalse\n",
    "\t\tmax_vol <float>: volumen máximo del embalse\n",
    "\t\tstart_vol <float>: volumen inicial del embalse\n",
    "\t\tend_vol <float>: volumen final del embalse\n",
    "\t\tactive <bool>: indica si el embalse está activo\n",
    "\t\t(?) hyd_independant <bool>: parámetro no identificado\n",
    "\t\t(?) future_cost <unknown>: parámetro no identificado\n",
    "\t\t(?) cmin <unknown>: cota m.s.n.m mínima\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "reshydricfilas_aux=[]\n",
    "for x in range(nres): # Para cada linea\n",
    "\taux=[]\n",
    "\tidaux=indexres['id'][x]\n",
    "\tname=indexres['EmbName'][x]\n",
    "\tjunction_id = junctionsinfo[junctionsinfo['CenName']==name]['id'].values[0]\n",
    "\t\n",
    "\taux.append(idaux)\n",
    "\taux.append(junction_id)\n",
    "\taux.append(name)\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['type'].values[0])\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembMin'].values[0])\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembMax'].values[0])\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembIn'].values[0])\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['VembFin'].values[0])\n",
    "\taux.append(1)\n",
    "\taux.append(0)\n",
    "\taux.append(None)\n",
    "\taux.append(reservoirsinfo[reservoirsinfo['id']==idaux]['cotaMínima'].values[0])\n",
    "\treshydricfilas_aux.append(aux)\n",
    "\n",
    "reshydric=pd.DataFrame(reshydricfilas_aux,columns=['id','junction_id','name','type','min_vol','max_vol','start_vol','end_vol','active','hyd_independant','future_cost','cmin'])\n",
    "\n",
    "reshydric.to_json(hydricTopology+\"/reservoirs.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\t(*) id <int>: identificador de la unión\n",
    "\t(*) name <str>: nombre de la unión\n",
    "\tlongitude <float>\n",
    "\tlatitude <float>\n",
    "\tactive <bool>: indica si la barra está activa\n",
    "\tdrainage <bool>: parámetro no identificado\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "junctionhydricfilas_aux=[]\n",
    "for x in range(len(junctionsinfo)): # Para cada junction\n",
    "\tlatitud,longitud=aleatory_direction()\n",
    "\taux=[]\n",
    "\taux.append(junctionsinfo['id'][x])\n",
    "\taux.append(junctionsinfo['CenName'][x])\n",
    "\taux.append(longitud)\n",
    "\taux.append(latitud)\n",
    "\taux.append(1)\n",
    "\taux.append(0)\n",
    "\t\n",
    "\tjunctionhydricfilas_aux.append(aux)\n",
    "\n",
    "junctionhydric=pd.DataFrame(junctionhydricfilas_aux,columns=['id','name','logitude','latitude','active','drainage'])\n",
    "\n",
    "junctionhydric.to_json(hydricTopology+\"/junctions.json\",orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embalse</th>\n",
       "      <th>type</th>\n",
       "      <th>central</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIPRESES</td>\n",
       "      <td>filtration</td>\n",
       "      <td>filt_cipreses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELTORO</td>\n",
       "      <td>filtration</td>\n",
       "      <td>ABANICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COLBUN</td>\n",
       "      <td>filtration</td>\n",
       "      <td>SAN_CLEMENTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COLBUN</td>\n",
       "      <td>extraction</td>\n",
       "      <td>CHIBURGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COLBUN</td>\n",
       "      <td>extraction</td>\n",
       "      <td>BPretilCol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RALCO</td>\n",
       "      <td>extraction</td>\n",
       "      <td>PALMUCHO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    embalse        type        central\n",
       "0  CIPRESES  filtration  filt_cipreses\n",
       "1    ELTORO  filtration        ABANICO\n",
       "2    COLBUN  filtration   SAN_CLEMENTE\n",
       "3    COLBUN  extraction       CHIBURGO\n",
       "4    COLBUN  extraction     BPretilCol\n",
       "5     RALCO  extraction       PALMUCHO"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydric_adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CenName</th>\n",
       "      <th>type</th>\n",
       "      <th>CVar</th>\n",
       "      <th>effinciency</th>\n",
       "      <th>bus_id</th>\n",
       "      <th>serie_hidro_gen</th>\n",
       "      <th>serie_hidro_ver</th>\n",
       "      <th>min_power</th>\n",
       "      <th>max_power</th>\n",
       "      <th>VembIn</th>\n",
       "      <th>VembFin</th>\n",
       "      <th>VembMin</th>\n",
       "      <th>VembMax</th>\n",
       "      <th>cotaMínima</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>COLBUN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.53</td>\n",
       "      <td>128.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>1183.820764</td>\n",
       "      <td>1553.245913</td>\n",
       "      <td>381.6242997</td>\n",
       "      <td>1553.245913</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id CenName type CVar effinciency  bus_id  serie_hidro_gen  \\\n",
       "27  28  COLBUN    E  NaN        1.53   128.0             33.0   \n",
       "\n",
       "    serie_hidro_ver min_power max_power       VembIn      VembFin  \\\n",
       "27              NaN         0       474  1183.820764  1553.245913   \n",
       "\n",
       "        VembMin      VembMax cotaMínima  \n",
       "27  381.6242997  1553.245913        397  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junctionsinfo[junctionsinfo['CenName']=='COLBUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embalse</th>\n",
       "      <th>type</th>\n",
       "      <th>central</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COLBUN</td>\n",
       "      <td>filtration</td>\n",
       "      <td>SAN_CLEMENTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COLBUN</td>\n",
       "      <td>extraction</td>\n",
       "      <td>CHIBURGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COLBUN</td>\n",
       "      <td>extraction</td>\n",
       "      <td>BPretilCol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embalse        type       central\n",
       "2  COLBUN  filtration  SAN_CLEMENTE\n",
       "3  COLBUN  extraction      CHIBURGO\n",
       "4  COLBUN  extraction    BPretilCol"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydric_adicional[hydric_adicional['embalse'] == \"COLBUN\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "        (*) id <int>: identificador del canal\n",
    "\t\t(*) name <str>: nombre del canal\n",
    "\t\t(*) type <str>: tipo de waterway\n",
    "\t\t(*) junc_a_id <int>: id de la unión de origen\n",
    "\t\t(*) junc_b_id <int>: id de la unión de destino\n",
    "\t\tactive <bool>: indica si el canal está activo\n",
    "\t\t(?) fmin <unknown>: parámetro no identificado\n",
    "\t\t(?) fmax <unknown>: parámetro no identificado\n",
    "\t\t(?) cvar <unknown>: parámetro no identificado \n",
    "        (?) delay <unknown>: parámetro no identificado\n",
    "\n",
    "'''\n",
    "\n",
    "junctionhydricfilas_aux=[]\n",
    "countid=1\n",
    "for x in range(len(junctionsinfo)):\n",
    "    gen_id=junctionsinfo.serie_hidro_gen[x]\n",
    "    ver_id=junctionsinfo.serie_hidro_ver[x]\n",
    "    name_a = junctionsinfo.CenName[x]\n",
    "    df_adicional = hydric_adicional[hydric_adicional['embalse'] == name_a]\n",
    "    if not pd.isnull(gen_id):\n",
    "        aux=[]\n",
    "        aux.append(countid)\n",
    "        countid+=1\n",
    "        name_b = junctionsinfo[junctionsinfo['id']==gen_id].CenName.values[0]\n",
    "        name = name_a+'_Gen_'+name_b\n",
    "        aux.append(name)\n",
    "        aux.append(\"generation\")\n",
    "        aux.append(junctionsinfo.id[x])\n",
    "        aux.append(gen_id)\n",
    "        aux.append(1)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        junctionhydricfilas_aux.append(aux)\n",
    "\n",
    "    if not pd.isnull(ver_id):\n",
    "        aux=[]\n",
    "        aux.append(countid)\n",
    "        countid+=1\n",
    "        name_b = junctionsinfo[junctionsinfo['id']==ver_id].CenName.values[0]\n",
    "        name = name_a+'_Vert_'+name_b\n",
    "        aux.append(name)\n",
    "        aux.append(\"spillover\")\n",
    "        aux.append(junctionsinfo.id[x])\n",
    "        aux.append(ver_id)\n",
    "        aux.append(1)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        aux.append(None)\n",
    "        junctionhydricfilas_aux.append(aux)\n",
    "    if len(df_adicional)>0:\n",
    "        for i in range(len(df_adicional)):\n",
    "            tipo =df_adicional['type'].iloc[i]\n",
    "            name =\"\"\n",
    "            central = df_adicional['central'].iloc[i].lower()\n",
    "            id_central = centralsinfo[centralsinfo['CenName'].str.lower() == central]['id'].values[0]\n",
    "            aux=[]\n",
    "            aux.append(countid)\n",
    "            countid+=1\n",
    "            name_b = junctionsinfo[junctionsinfo['id']==id_central].CenName.values[0]\n",
    "            if tipo == \"filtration\":\n",
    "                name = name_a+'_Fil_'+name_b\n",
    "            elif tipo == \"extraction\":\n",
    "                name = name_a+'_Ext_'+name_b\n",
    "            aux.append(name)\n",
    "            aux.append(tipo)\n",
    "            aux.append(junctionsinfo.id[x])\n",
    "            aux.append(id_central)\n",
    "            aux.append(1)\n",
    "            aux.append(None)\n",
    "            aux.append(None)\n",
    "            aux.append(None)\n",
    "            aux.append(None)\n",
    "            junctionhydricfilas_aux.append(aux)\n",
    "   \n",
    "\n",
    "waterwayshydric=pd.DataFrame(junctionhydricfilas_aux,columns=[\"id\",\"name\",\"type\",\"junc_a_id\",\"junc_b_id\",\"active\",\"fmin\",\"fmax\",\"cvar\",\"delay\"])\n",
    "waterwayshydric.to_json(hydricTopology+\"/waterways.json\",orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>junc_a_id</th>\n",
       "      <th>junc_b_id</th>\n",
       "      <th>active</th>\n",
       "      <th>fmin</th>\n",
       "      <th>fmax</th>\n",
       "      <th>cvar</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>COLBUN_Gen_MACHICURA</td>\n",
       "      <td>generation</td>\n",
       "      <td>28</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>COLBUN_Fil_SAN_CLEMENTE</td>\n",
       "      <td>filtration</td>\n",
       "      <td>28</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>COLBUN_Ext_CHIBURGO</td>\n",
       "      <td>extraction</td>\n",
       "      <td>28</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>COLBUN_Ext_BPretilCol</td>\n",
       "      <td>extraction</td>\n",
       "      <td>28</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                     name        type  junc_a_id  junc_b_id  active  \\\n",
       "46  47     COLBUN_Gen_MACHICURA  generation         28       33.0       1   \n",
       "47  48  COLBUN_Fil_SAN_CLEMENTE  filtration         28       31.0       1   \n",
       "48  49      COLBUN_Ext_CHIBURGO  extraction         28       29.0       1   \n",
       "49  50    COLBUN_Ext_BPretilCol  extraction         28       26.0       1   \n",
       "\n",
       "    fmin  fmax  cvar delay  \n",
       "46  None  None  None  None  \n",
       "47  None  None  None  None  \n",
       "48  None  None  None  None  \n",
       "49  None  None  None  None  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waterwayshydric[waterwayshydric['junc_a_id']==28]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
